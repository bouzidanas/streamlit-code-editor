{"ast":null,"code":"// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Schema, Field } from '../../schema';\nimport { Dictionary, Utf8, Binary, Decimal, FixedSizeBinary, List, FixedSizeList, Map_, Struct, Union, Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, Int32 } from '../../type';\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n/** @ignore */\nexport function schemaFromJSON(_schema) {\n  let dictionaries = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : new Map();\n  return new Schema(schemaFieldsFromJSON(_schema, dictionaries), customMetadataFromJSON(_schema['customMetadata']), dictionaries);\n}\n/** @ignore */\nexport function recordBatchFromJSON(b) {\n  return new RecordBatch(b['count'], fieldNodesFromJSON(b['columns']), buffersFromJSON(b['columns']));\n}\n/** @ignore */\nexport function dictionaryBatchFromJSON(b) {\n  return new DictionaryBatch(recordBatchFromJSON(b['data']), b['id'], b['isDelta']);\n}\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema, dictionaries) {\n  return (_schema['fields'] || []).filter(Boolean).map(f => Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\nfunction fieldChildrenFromJSON(_field, dictionaries) {\n  return (_field['children'] || []).filter(Boolean).map(f => Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\nfunction fieldNodesFromJSON(xs) {\n  return (xs || []).reduce((fieldNodes, column) => [...fieldNodes, new FieldNode(column['count'], nullCountFromJSON(column['VALIDITY'])), ...fieldNodesFromJSON(column['children'])], []);\n}\n/** @ignore */\nfunction buffersFromJSON(xs) {\n  let buffers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n  for (let i = -1, n = (xs || []).length; ++i < n;) {\n    const column = xs[i];\n    column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n    column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n    column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n    column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n    buffers = buffersFromJSON(column['children'], buffers);\n  }\n  return buffers;\n}\n/** @ignore */\nfunction nullCountFromJSON(validity) {\n  return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n/** @ignore */\nexport function fieldFromJSON(_field, dictionaries) {\n  let id;\n  let keys;\n  let field;\n  let dictMeta;\n  let type;\n  let dictType;\n  // If no dictionary encoding\n  if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n    type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n    field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  // tslint:disable\n  // If dictionary encoded and the first time we've seen this dictionary id, decode\n  // the data type and child fields, then wrap in a Dictionary type and insert the\n  // data type into the dictionary types map.\n  else if (!dictionaries.has(id = dictMeta['id'])) {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n    dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n  // data type and wrap in a new Dictionary type and field.\n  else {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictType = new Dictionary(dictionaries.get(id), keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  return field || null;\n}\n/** @ignore */\nfunction customMetadataFromJSON(_metadata) {\n  return new Map(Object.entries(_metadata || {}));\n}\n/** @ignore */\nfunction indexTypeFromJSON(_type) {\n  return new Int(_type['isSigned'], _type['bitWidth']);\n}\n/** @ignore */\nfunction typeFromJSON(f, children) {\n  const typeId = f['type']['name'];\n  switch (typeId) {\n    case 'NONE':\n      return new Null();\n    case 'null':\n      return new Null();\n    case 'binary':\n      return new Binary();\n    case 'utf8':\n      return new Utf8();\n    case 'bool':\n      return new Bool();\n    case 'list':\n      return new List((children || [])[0]);\n    case 'struct':\n      return new Struct(children || []);\n    case 'struct_':\n      return new Struct(children || []);\n  }\n  switch (typeId) {\n    case 'int':\n      {\n        const t = f['type'];\n        return new Int(t['isSigned'], t['bitWidth']);\n      }\n    case 'floatingpoint':\n      {\n        const t = f['type'];\n        return new Float(Precision[t['precision']]);\n      }\n    case 'decimal':\n      {\n        const t = f['type'];\n        return new Decimal(t['scale'], t['precision']);\n      }\n    case 'date':\n      {\n        const t = f['type'];\n        return new Date_(DateUnit[t['unit']]);\n      }\n    case 'time':\n      {\n        const t = f['type'];\n        return new Time(TimeUnit[t['unit']], t['bitWidth']);\n      }\n    case 'timestamp':\n      {\n        const t = f['type'];\n        return new Timestamp(TimeUnit[t['unit']], t['timezone']);\n      }\n    case 'interval':\n      {\n        const t = f['type'];\n        return new Interval(IntervalUnit[t['unit']]);\n      }\n    case 'union':\n      {\n        const t = f['type'];\n        return new Union(UnionMode[t['mode']], t['typeIds'] || [], children || []);\n      }\n    case 'fixedsizebinary':\n      {\n        const t = f['type'];\n        return new FixedSizeBinary(t['byteWidth']);\n      }\n    case 'fixedsizelist':\n      {\n        const t = f['type'];\n        return new FixedSizeList(t['listSize'], (children || [])[0]);\n      }\n    case 'map':\n      {\n        const t = f['type'];\n        return new Map_((children || [])[0], t['keysSorted']);\n      }\n  }\n  throw new Error(\"Unrecognized type: \\\"\".concat(typeId, \"\\\"\"));\n}","map":{"version":3,"names":["Schema","Field","Dictionary","Utf8","Binary","Decimal","FixedSizeBinary","List","FixedSizeList","Map_","Struct","Union","Bool","Null","Int","Float","Date_","Time","Interval","Timestamp","Int32","DictionaryBatch","RecordBatch","FieldNode","BufferRegion","TimeUnit","Precision","IntervalUnit","UnionMode","DateUnit","schemaFromJSON","_schema","dictionaries","arguments","length","undefined","Map","schemaFieldsFromJSON","customMetadataFromJSON","recordBatchFromJSON","b","fieldNodesFromJSON","buffersFromJSON","dictionaryBatchFromJSON","filter","Boolean","map","f","fromJSON","fieldChildrenFromJSON","_field","xs","reduce","fieldNodes","column","nullCountFromJSON","buffers","i","n","push","validity","sum","val","fieldFromJSON","id","keys","field","dictMeta","type","dictType","typeFromJSON","has","indexTypeFromJSON","set","get","_metadata","Object","entries","_type","children","typeId","t","Error","concat"],"sources":["ipc/metadata/json.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Schema, Field } from '../../schema';\nimport {\n    DataType, Dictionary, TimeBitWidth,\n    Utf8, Binary, Decimal, FixedSizeBinary,\n    List, FixedSizeList, Map_, Struct, Union,\n    Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, IntBitWidth, Int32, TKeys,\n} from '../../type';\n\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n\n/** @ignore */\nexport function schemaFromJSON(_schema: any, dictionaries: Map<number, DataType> = new Map()) {\n    return new Schema(\n        schemaFieldsFromJSON(_schema, dictionaries),\n        customMetadataFromJSON(_schema['customMetadata']),\n        dictionaries\n    );\n}\n\n/** @ignore */\nexport function recordBatchFromJSON(b: any) {\n    return new RecordBatch(\n        b['count'],\n        fieldNodesFromJSON(b['columns']),\n        buffersFromJSON(b['columns'])\n    );\n}\n\n/** @ignore */\nexport function dictionaryBatchFromJSON(b: any) {\n    return new DictionaryBatch(\n        recordBatchFromJSON(b['data']),\n        b['id'], b['isDelta']\n    );\n}\n\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema: any, dictionaries?: Map<number, DataType>) {\n    return (_schema['fields'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldChildrenFromJSON(_field: any, dictionaries?: Map<number, DataType>): Field[] {\n    return (_field['children'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldNodesFromJSON(xs: any[]): FieldNode[] {\n    return (xs || []).reduce<FieldNode[]>((fieldNodes, column: any) => [\n        ...fieldNodes,\n        new FieldNode(\n            column['count'],\n            nullCountFromJSON(column['VALIDITY'])\n        ),\n        ...fieldNodesFromJSON(column['children'])\n    ], [] as FieldNode[]);\n}\n\n/** @ignore */\nfunction buffersFromJSON(xs: any[], buffers: BufferRegion[] = []): BufferRegion[] {\n    for (let i = -1, n = (xs || []).length; ++i < n;) {\n        const column = xs[i];\n        column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n        column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n        column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n        column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n        buffers = buffersFromJSON(column['children'], buffers);\n    }\n    return buffers;\n}\n\n/** @ignore */\nfunction nullCountFromJSON(validity: number[]) {\n    return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n\n/** @ignore */\nexport function fieldFromJSON(_field: any, dictionaries?: Map<number, DataType>) {\n\n    let id: number;\n    let keys: TKeys | null;\n    let field: Field | void;\n    let dictMeta: any;\n    let type: DataType<any>;\n    let dictType: Dictionary;\n\n    // If no dictionary encoding\n    if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n        type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n        field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // tslint:disable\n    // If dictionary encoded and the first time we've seen this dictionary id, decode\n    // the data type and child fields, then wrap in a Dictionary type and insert the\n    // data type into the dictionary types map.\n    else if (!dictionaries.has(id = dictMeta['id'])) {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n        dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n    // data type and wrap in a new Dictionary type and field.\n    else {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictType = new Dictionary(dictionaries.get(id)!, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    return field || null;\n}\n\n/** @ignore */\nfunction customMetadataFromJSON(_metadata?: object) {\n    return new Map<string, string>(Object.entries(_metadata || {}));\n}\n\n/** @ignore */\nfunction indexTypeFromJSON(_type: any) {\n    return new Int(_type['isSigned'], _type['bitWidth']);\n}\n\n/** @ignore */\nfunction typeFromJSON(f: any, children?: Field[]): DataType<any> {\n\n    const typeId = f['type']['name'];\n\n    switch (typeId) {\n        case 'NONE':   return new Null();\n        case 'null':   return new Null();\n        case 'binary': return new Binary();\n        case 'utf8':   return new Utf8();\n        case 'bool':   return new Bool();\n        case 'list':   return new List((children || [])[0]);\n        case 'struct': return new Struct(children || []);\n        case 'struct_': return new Struct(children || []);\n    }\n\n    switch (typeId) {\n        case 'int': {\n            const t = f['type'];\n            return new Int(t['isSigned'], t['bitWidth'] as IntBitWidth);\n        }\n        case 'floatingpoint': {\n            const t = f['type'];\n            return new Float(Precision[t['precision']] as any);\n        }\n        case 'decimal': {\n            const t = f['type'];\n            return new Decimal(t['scale'], t['precision']);\n        }\n        case 'date': {\n            const t = f['type'];\n            return new Date_(DateUnit[t['unit']] as any);\n        }\n        case 'time': {\n            const t = f['type'];\n            return new Time(TimeUnit[t['unit']] as any, t['bitWidth'] as TimeBitWidth);\n        }\n        case 'timestamp': {\n            const t = f['type'];\n            return new Timestamp(TimeUnit[t['unit']] as any, t['timezone']);\n        }\n        case 'interval': {\n            const t = f['type'];\n            return new Interval(IntervalUnit[t['unit']] as any);\n        }\n        case 'union': {\n            const t = f['type'];\n            return new Union(UnionMode[t['mode']] as any, (t['typeIds'] || []), children || []);\n        }\n        case 'fixedsizebinary': {\n            const t = f['type'];\n            return new FixedSizeBinary(t['byteWidth']);\n        }\n        case 'fixedsizelist': {\n            const t = f['type'];\n            return new FixedSizeList(t['listSize'], (children || [])[0]);\n        }\n        case 'map': {\n            const t = f['type'];\n            return new Map_((children || [])[0], t['keysSorted']);\n        }\n    }\n    throw new Error(`Unrecognized type: \"${typeId}\"`);\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAASA,MAAM,EAAEC,KAAK,QAAQ,cAAc;AAC5C,SACcC,UAAU,EACpBC,IAAI,EAAEC,MAAM,EAAEC,OAAO,EAAEC,eAAe,EACtCC,IAAI,EAAEC,aAAa,EAAEC,IAAI,EAAEC,MAAM,EAAEC,KAAK,EACxCC,IAAI,EAAEC,IAAI,EAAEC,GAAG,EAAEC,KAAK,EAAEC,KAAK,EAAEC,IAAI,EAAEC,QAAQ,EAAEC,SAAS,EAAeC,KAAK,QACzE,YAAY;AAEnB,SAASC,eAAe,EAAEC,WAAW,EAAEC,SAAS,EAAEC,YAAY,QAAQ,WAAW;AACjF,SAASC,QAAQ,EAAEC,SAAS,EAAEC,YAAY,EAAEC,SAAS,EAAEC,QAAQ,QAAQ,YAAY;AAEnF;AACA,OAAM,SAAUC,cAAcA,CAACC,OAAY,EAAiD;EAAA,IAA/CC,YAAA,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAsC,IAAIG,GAAG,EAAE;EACxF,OAAO,IAAIpC,MAAM,CACbqC,oBAAoB,CAACN,OAAO,EAAEC,YAAY,CAAC,EAC3CM,sBAAsB,CAACP,OAAO,CAAC,gBAAgB,CAAC,CAAC,EACjDC,YAAY,CACf;AACL;AAEA;AACA,OAAM,SAAUO,mBAAmBA,CAACC,CAAM;EACtC,OAAO,IAAIlB,WAAW,CAClBkB,CAAC,CAAC,OAAO,CAAC,EACVC,kBAAkB,CAACD,CAAC,CAAC,SAAS,CAAC,CAAC,EAChCE,eAAe,CAACF,CAAC,CAAC,SAAS,CAAC,CAAC,CAChC;AACL;AAEA;AACA,OAAM,SAAUG,uBAAuBA,CAACH,CAAM;EAC1C,OAAO,IAAInB,eAAe,CACtBkB,mBAAmB,CAACC,CAAC,CAAC,MAAM,CAAC,CAAC,EAC9BA,CAAC,CAAC,IAAI,CAAC,EAAEA,CAAC,CAAC,SAAS,CAAC,CACxB;AACL;AAEA;AACA,SAASH,oBAAoBA,CAACN,OAAY,EAAEC,YAAoC;EAC5E,OAAO,CAACD,OAAO,CAAC,QAAQ,CAAC,IAAI,EAAE,EAAEa,MAAM,CAACC,OAAO,CAAC,CAACC,GAAG,CAAEC,CAAM,IAAK9C,KAAK,CAAC+C,QAAQ,CAACD,CAAC,EAAEf,YAAY,CAAC,CAAC;AACrG;AAEA;AACA,SAASiB,qBAAqBA,CAACC,MAAW,EAAElB,YAAoC;EAC5E,OAAO,CAACkB,MAAM,CAAC,UAAU,CAAC,IAAI,EAAE,EAAEN,MAAM,CAACC,OAAO,CAAC,CAACC,GAAG,CAAEC,CAAM,IAAK9C,KAAK,CAAC+C,QAAQ,CAACD,CAAC,EAAEf,YAAY,CAAC,CAAC;AACtG;AAEA;AACA,SAASS,kBAAkBA,CAACU,EAAS;EACjC,OAAO,CAACA,EAAE,IAAI,EAAE,EAAEC,MAAM,CAAc,CAACC,UAAU,EAAEC,MAAW,KAAK,CAC/D,GAAGD,UAAU,EACb,IAAI9B,SAAS,CACT+B,MAAM,CAAC,OAAO,CAAC,EACfC,iBAAiB,CAACD,MAAM,CAAC,UAAU,CAAC,CAAC,CACxC,EACD,GAAGb,kBAAkB,CAACa,MAAM,CAAC,UAAU,CAAC,CAAC,CAC5C,EAAE,EAAiB,CAAC;AACzB;AAEA;AACA,SAASZ,eAAeA,CAACS,EAAS,EAA8B;EAAA,IAA5BK,OAAA,GAAAvB,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAA0B,EAAE;EAC5D,KAAK,IAAIwB,CAAC,GAAG,CAAC,CAAC,EAAEC,CAAC,GAAG,CAACP,EAAE,IAAI,EAAE,EAAEjB,MAAM,EAAE,EAAEuB,CAAC,GAAGC,CAAC,GAAG;IAC9C,MAAMJ,MAAM,GAAGH,EAAE,CAACM,CAAC,CAAC;IACpBH,MAAM,CAAC,UAAU,CAAC,IAAIE,OAAO,CAACG,IAAI,CAAC,IAAInC,YAAY,CAACgC,OAAO,CAACtB,MAAM,EAAEoB,MAAM,CAAC,UAAU,CAAC,CAACpB,MAAM,CAAC,CAAC;IAC/FoB,MAAM,CAAC,MAAM,CAAC,IAAIE,OAAO,CAACG,IAAI,CAAC,IAAInC,YAAY,CAACgC,OAAO,CAACtB,MAAM,EAAEoB,MAAM,CAAC,MAAM,CAAC,CAACpB,MAAM,CAAC,CAAC;IACvFoB,MAAM,CAAC,QAAQ,CAAC,IAAIE,OAAO,CAACG,IAAI,CAAC,IAAInC,YAAY,CAACgC,OAAO,CAACtB,MAAM,EAAEoB,MAAM,CAAC,QAAQ,CAAC,CAACpB,MAAM,CAAC,CAAC;IAC3FoB,MAAM,CAAC,MAAM,CAAC,IAAIE,OAAO,CAACG,IAAI,CAAC,IAAInC,YAAY,CAACgC,OAAO,CAACtB,MAAM,EAAEoB,MAAM,CAAC,MAAM,CAAC,CAACpB,MAAM,CAAC,CAAC;IACvFsB,OAAO,GAAGd,eAAe,CAACY,MAAM,CAAC,UAAU,CAAC,EAAEE,OAAO,CAAC;;EAE1D,OAAOA,OAAO;AAClB;AAEA;AACA,SAASD,iBAAiBA,CAACK,QAAkB;EACzC,OAAO,CAACA,QAAQ,IAAI,EAAE,EAAER,MAAM,CAAC,CAACS,GAAG,EAAEC,GAAG,KAAKD,GAAG,GAAG,EAAEC,GAAG,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC;AACvE;AAEA;AACA,OAAM,SAAUC,aAAaA,CAACb,MAAW,EAAElB,YAAoC;EAE3E,IAAIgC,EAAU;EACd,IAAIC,IAAkB;EACtB,IAAIC,KAAmB;EACvB,IAAIC,QAAa;EACjB,IAAIC,IAAmB;EACvB,IAAIC,QAAoB;EAExB;EACA,IAAI,CAACrC,YAAY,IAAI,EAAEmC,QAAQ,GAAGjB,MAAM,CAAC,YAAY,CAAC,CAAC,EAAE;IACrDkB,IAAI,GAAGE,YAAY,CAACpB,MAAM,EAAED,qBAAqB,CAACC,MAAM,EAAElB,YAAY,CAAC,CAAC;IACxEkC,KAAK,GAAG,IAAIjE,KAAK,CAACiD,MAAM,CAAC,MAAM,CAAC,EAAEkB,IAAI,EAAElB,MAAM,CAAC,UAAU,CAAC,EAAEZ,sBAAsB,CAACY,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;;EAEjH;EACA;EACA;EACA;EAAA,KACK,IAAI,CAAClB,YAAY,CAACuC,GAAG,CAACP,EAAE,GAAGG,QAAQ,CAAC,IAAI,CAAC,CAAC,EAAE;IAC7C;IACAF,IAAI,GAAG,CAACA,IAAI,GAAGE,QAAQ,CAAC,WAAW,CAAC,IAAIK,iBAAiB,CAACP,IAAI,CAAU,GAAG,IAAI7C,KAAK,EAAE;IACtFY,YAAY,CAACyC,GAAG,CAACT,EAAE,EAAEI,IAAI,GAAGE,YAAY,CAACpB,MAAM,EAAED,qBAAqB,CAACC,MAAM,EAAElB,YAAY,CAAC,CAAC,CAAC;IAC9FqC,QAAQ,GAAG,IAAInE,UAAU,CAACkE,IAAI,EAAEH,IAAI,EAAED,EAAE,EAAEG,QAAQ,CAAC,WAAW,CAAC,CAAC;IAChED,KAAK,GAAG,IAAIjE,KAAK,CAACiD,MAAM,CAAC,MAAM,CAAC,EAAEmB,QAAQ,EAAEnB,MAAM,CAAC,UAAU,CAAC,EAAEZ,sBAAsB,CAACY,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;;EAErH;EACA;EAAA,KACK;IACD;IACAe,IAAI,GAAG,CAACA,IAAI,GAAGE,QAAQ,CAAC,WAAW,CAAC,IAAIK,iBAAiB,CAACP,IAAI,CAAU,GAAG,IAAI7C,KAAK,EAAE;IACtFiD,QAAQ,GAAG,IAAInE,UAAU,CAAC8B,YAAY,CAAC0C,GAAG,CAACV,EAAE,CAAE,EAAEC,IAAI,EAAED,EAAE,EAAEG,QAAQ,CAAC,WAAW,CAAC,CAAC;IACjFD,KAAK,GAAG,IAAIjE,KAAK,CAACiD,MAAM,CAAC,MAAM,CAAC,EAAEmB,QAAQ,EAAEnB,MAAM,CAAC,UAAU,CAAC,EAAEZ,sBAAsB,CAACY,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;;EAErH,OAAOgB,KAAK,IAAI,IAAI;AACxB;AAEA;AACA,SAAS5B,sBAAsBA,CAACqC,SAAkB;EAC9C,OAAO,IAAIvC,GAAG,CAAiBwC,MAAM,CAACC,OAAO,CAACF,SAAS,IAAI,EAAE,CAAC,CAAC;AACnE;AAEA;AACA,SAASH,iBAAiBA,CAACM,KAAU;EACjC,OAAO,IAAIhE,GAAG,CAACgE,KAAK,CAAC,UAAU,CAAC,EAAEA,KAAK,CAAC,UAAU,CAAC,CAAC;AACxD;AAEA;AACA,SAASR,YAAYA,CAACvB,CAAM,EAAEgC,QAAkB;EAE5C,MAAMC,MAAM,GAAGjC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC;EAEhC,QAAQiC,MAAM;IACV,KAAK,MAAM;MAAI,OAAO,IAAInE,IAAI,EAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAIA,IAAI,EAAE;IAChC,KAAK,QAAQ;MAAE,OAAO,IAAIT,MAAM,EAAE;IAClC,KAAK,MAAM;MAAI,OAAO,IAAID,IAAI,EAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAIS,IAAI,EAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAIL,IAAI,CAAC,CAACwE,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,CAAC;IACnD,KAAK,QAAQ;MAAE,OAAO,IAAIrE,MAAM,CAACqE,QAAQ,IAAI,EAAE,CAAC;IAChD,KAAK,SAAS;MAAE,OAAO,IAAIrE,MAAM,CAACqE,QAAQ,IAAI,EAAE,CAAC;;EAGrD,QAAQC,MAAM;IACV,KAAK,KAAK;MAAE;QACR,MAAMC,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIjC,GAAG,CAACmE,CAAC,CAAC,UAAU,CAAC,EAAEA,CAAC,CAAC,UAAU,CAAgB,CAAC;;IAE/D,KAAK,eAAe;MAAE;QAClB,MAAMA,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIhC,KAAK,CAACW,SAAS,CAACuD,CAAC,CAAC,WAAW,CAAC,CAAQ,CAAC;;IAEtD,KAAK,SAAS;MAAE;QACZ,MAAMA,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI1C,OAAO,CAAC4E,CAAC,CAAC,OAAO,CAAC,EAAEA,CAAC,CAAC,WAAW,CAAC,CAAC;;IAElD,KAAK,MAAM;MAAE;QACT,MAAMA,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI/B,KAAK,CAACa,QAAQ,CAACoD,CAAC,CAAC,MAAM,CAAC,CAAQ,CAAC;;IAEhD,KAAK,MAAM;MAAE;QACT,MAAMA,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI9B,IAAI,CAACQ,QAAQ,CAACwD,CAAC,CAAC,MAAM,CAAC,CAAQ,EAAEA,CAAC,CAAC,UAAU,CAAiB,CAAC;;IAE9E,KAAK,WAAW;MAAE;QACd,MAAMA,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI5B,SAAS,CAACM,QAAQ,CAACwD,CAAC,CAAC,MAAM,CAAC,CAAQ,EAAEA,CAAC,CAAC,UAAU,CAAC,CAAC;;IAEnE,KAAK,UAAU;MAAE;QACb,MAAMA,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI7B,QAAQ,CAACS,YAAY,CAACsD,CAAC,CAAC,MAAM,CAAC,CAAQ,CAAC;;IAEvD,KAAK,OAAO;MAAE;QACV,MAAMA,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIpC,KAAK,CAACiB,SAAS,CAACqD,CAAC,CAAC,MAAM,CAAC,CAAQ,EAAGA,CAAC,CAAC,SAAS,CAAC,IAAI,EAAE,EAAGF,QAAQ,IAAI,EAAE,CAAC;;IAEvF,KAAK,iBAAiB;MAAE;QACpB,MAAME,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIzC,eAAe,CAAC2E,CAAC,CAAC,WAAW,CAAC,CAAC;;IAE9C,KAAK,eAAe;MAAE;QAClB,MAAMA,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIvC,aAAa,CAACyE,CAAC,CAAC,UAAU,CAAC,EAAE,CAACF,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,CAAC;;IAEhE,KAAK,KAAK;MAAE;QACR,MAAME,CAAC,GAAGlC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAItC,IAAI,CAAC,CAACsE,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,EAAEE,CAAC,CAAC,YAAY,CAAC,CAAC;;;EAG7D,MAAM,IAAIC,KAAK,yBAAAC,MAAA,CAAwBH,MAAM,OAAG,CAAC;AACrD","ignoreList":[]},"metadata":{},"sourceType":"module"}