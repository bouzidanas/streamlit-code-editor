{"ast":null,"code":"// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Table } from '../table';\nimport { MAGIC } from './message';\nimport { Column } from '../column';\nimport { DataType } from '../type';\nimport { Field } from '../schema';\nimport { Message } from './metadata/message';\nimport * as metadata from './metadata/message';\nimport { FileBlock, Footer } from './metadata/file';\nimport { MessageHeader, MetadataVersion } from '../enum';\nimport { AsyncByteQueue } from '../io/stream';\nimport { VectorAssembler } from '../visitor/vectorassembler';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler';\nimport { toUint8Array } from '../util/buffer';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch';\nimport { ReadableInterop } from '../io/interfaces';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat';\nexport class RecordBatchWriter extends ReadableInterop {\n  constructor(options) {\n    super();\n    this._position = 0;\n    this._started = false;\n    // @ts-ignore\n    this._sink = new AsyncByteQueue();\n    this._schema = null;\n    this._dictionaryBlocks = [];\n    this._recordBatchBlocks = [];\n    this._dictionaryDeltaOffsets = new Map();\n    isObject(options) || (options = {\n      autoDestroy: true,\n      writeLegacyIpcFormat: false\n    });\n    this._autoDestroy = typeof options.autoDestroy === 'boolean' ? options.autoDestroy : true;\n    this._writeLegacyIpcFormat = typeof options.writeLegacyIpcFormat === 'boolean' ? options.writeLegacyIpcFormat : false;\n  }\n  /** @nocollapse */\n  // @ts-ignore\n  static throughNode(options) {\n    throw new Error(\"\\\"throughNode\\\" not available in this environment\");\n  }\n  /** @nocollapse */\n  static throughDOM(\n  // @ts-ignore\n  writableStrategy,\n  // @ts-ignore\n  readableStrategy) {\n    throw new Error(\"\\\"throughDOM\\\" not available in this environment\");\n  }\n  toString() {\n    let sync = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n    return this._sink.toString(sync);\n  }\n  toUint8Array() {\n    let sync = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n    return this._sink.toUint8Array(sync);\n  }\n  writeAll(input) {\n    if (isPromise(input)) {\n      return input.then(x => this.writeAll(x));\n    } else if (isAsyncIterable(input)) {\n      return writeAllAsync(this, input);\n    }\n    return writeAll(this, input);\n  }\n  get closed() {\n    return this._sink.closed;\n  }\n  [Symbol.asyncIterator]() {\n    return this._sink[Symbol.asyncIterator]();\n  }\n  toDOMStream(options) {\n    return this._sink.toDOMStream(options);\n  }\n  toNodeStream(options) {\n    return this._sink.toNodeStream(options);\n  }\n  close() {\n    return this.reset()._sink.close();\n  }\n  abort(reason) {\n    return this.reset()._sink.abort(reason);\n  }\n  finish() {\n    this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n    return this;\n  }\n  reset() {\n    let sink = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this._sink;\n    let schema = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    if (sink === this._sink || sink instanceof AsyncByteQueue) {\n      this._sink = sink;\n    } else {\n      this._sink = new AsyncByteQueue();\n      if (sink && isWritableDOMStream(sink)) {\n        this.toDOMStream({\n          type: 'bytes'\n        }).pipeTo(sink);\n      } else if (sink && isWritableNodeStream(sink)) {\n        this.toNodeStream({\n          objectMode: false\n        }).pipe(sink);\n      }\n    }\n    if (this._started && this._schema) {\n      this._writeFooter(this._schema);\n    }\n    this._started = false;\n    this._dictionaryBlocks = [];\n    this._recordBatchBlocks = [];\n    this._dictionaryDeltaOffsets = new Map();\n    if (!schema || !schema.compareTo(this._schema)) {\n      if (schema === null) {\n        this._position = 0;\n        this._schema = null;\n      } else {\n        this._started = true;\n        this._schema = schema;\n        this._writeSchema(schema);\n      }\n    }\n    return this;\n  }\n  write(payload) {\n    let schema = null;\n    if (!this._sink) {\n      throw new Error(\"RecordBatchWriter is closed\");\n    } else if (payload === null || payload === undefined) {\n      return this.finish() && undefined;\n    } else if (payload instanceof Table && !(schema = payload.schema)) {\n      return this.finish() && undefined;\n    } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n      return this.finish() && undefined;\n    }\n    if (schema && !schema.compareTo(this._schema)) {\n      if (this._started && this._autoDestroy) {\n        return this.close();\n      }\n      this.reset(this._sink, schema);\n    }\n    if (payload instanceof RecordBatch) {\n      if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n        this._writeRecordBatch(payload);\n      }\n    } else if (payload instanceof Table) {\n      this.writeAll(payload.chunks);\n    } else if (isIterable(payload)) {\n      this.writeAll(payload);\n    }\n  }\n  _writeMessage(message) {\n    let alignment = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 8;\n    const a = alignment - 1;\n    const buffer = Message.encode(message);\n    const flatbufferSize = buffer.byteLength;\n    const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n    const alignedSize = flatbufferSize + prefixSize + a & ~a;\n    const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n    if (message.headerType === MessageHeader.RecordBatch) {\n      this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n    } else if (message.headerType === MessageHeader.DictionaryBatch) {\n      this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n    }\n    // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n    if (!this._writeLegacyIpcFormat) {\n      this._write(Int32Array.of(-1));\n    }\n    // Write the flatbuffer size prefix including padding\n    this._write(Int32Array.of(alignedSize - prefixSize));\n    // Write the flatbuffer\n    if (flatbufferSize > 0) {\n      this._write(buffer);\n    }\n    // Write any padding\n    return this._writePadding(nPaddingBytes);\n  }\n  _write(chunk) {\n    if (this._started) {\n      const buffer = toUint8Array(chunk);\n      if (buffer && buffer.byteLength > 0) {\n        this._sink.write(buffer);\n        this._position += buffer.byteLength;\n      }\n    }\n    return this;\n  }\n  _writeSchema(schema) {\n    return this._writeMessage(Message.from(schema));\n  }\n  // @ts-ignore\n  _writeFooter(schema) {\n    // eos bytes\n    return this._writeLegacyIpcFormat ? this._write(Int32Array.of(0)) : this._write(Int32Array.of(-1, 0));\n  }\n  _writeMagic() {\n    return this._write(MAGIC);\n  }\n  _writePadding(nBytes) {\n    return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n  }\n  _writeRecordBatch(batch) {\n    const {\n      byteLength,\n      nodes,\n      bufferRegions,\n      buffers\n    } = VectorAssembler.assemble(batch);\n    const recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n    const message = Message.from(recordBatch, byteLength);\n    return this._writeDictionaries(batch)._writeMessage(message)._writeBodyBuffers(buffers);\n  }\n  _writeDictionaryBatch(dictionary, id) {\n    let isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n    this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n    const {\n      byteLength,\n      nodes,\n      bufferRegions,\n      buffers\n    } = VectorAssembler.assemble(dictionary);\n    const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n    const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n    const message = Message.from(dictionaryBatch, byteLength);\n    return this._writeMessage(message)._writeBodyBuffers(buffers);\n  }\n  _writeBodyBuffers(buffers) {\n    let buffer;\n    let size, padding;\n    for (let i = -1, n = buffers.length; ++i < n;) {\n      if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n        this._write(buffer);\n        if ((padding = (size + 7 & ~7) - size) > 0) {\n          this._writePadding(padding);\n        }\n      }\n    }\n    return this;\n  }\n  _writeDictionaries(batch) {\n    for (let [id, dictionary] of batch.dictionaries) {\n      let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n      if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n        const chunks = 'chunks' in dictionary ? dictionary.chunks : [dictionary];\n        for (const chunk of chunks) {\n          this._writeDictionaryBatch(chunk, id, offset > 0);\n          offset += chunk.length;\n        }\n      }\n    }\n    return this;\n  }\n}\n/** @ignore */\nexport class RecordBatchStreamWriter extends RecordBatchWriter {\n  /** @nocollapse */\n  static writeAll(input, options) {\n    const writer = new RecordBatchStreamWriter(options);\n    if (isPromise(input)) {\n      return input.then(x => writer.writeAll(x));\n    } else if (isAsyncIterable(input)) {\n      return writeAllAsync(writer, input);\n    }\n    return writeAll(writer, input);\n  }\n}\n/** @ignore */\nexport class RecordBatchFileWriter extends RecordBatchWriter {\n  constructor() {\n    super();\n    this._autoDestroy = true;\n  }\n  /** @nocollapse */\n  static writeAll(input) {\n    const writer = new RecordBatchFileWriter();\n    if (isPromise(input)) {\n      return input.then(x => writer.writeAll(x));\n    } else if (isAsyncIterable(input)) {\n      return writeAllAsync(writer, input);\n    }\n    return writeAll(writer, input);\n  }\n  // @ts-ignore\n  _writeSchema(schema) {\n    return this._writeMagic()._writePadding(2);\n  }\n  _writeFooter(schema) {\n    const buffer = Footer.encode(new Footer(schema, MetadataVersion.V4, this._recordBatchBlocks, this._dictionaryBlocks));\n    return super._writeFooter(schema) // EOS bytes for sequential readers\n    ._write(buffer) // Write the flatbuffer\n    ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n    ._writeMagic(); // then the magic suffix\n  }\n}\n/** @ignore */\nexport class RecordBatchJSONWriter extends RecordBatchWriter {\n  constructor() {\n    super();\n    this._autoDestroy = true;\n    this._recordBatches = [];\n    this._dictionaries = [];\n  }\n  /** @nocollapse */\n  static writeAll(input) {\n    return new RecordBatchJSONWriter().writeAll(input);\n  }\n  _writeMessage() {\n    return this;\n  }\n  // @ts-ignore\n  _writeFooter(schema) {\n    return this;\n  }\n  _writeSchema(schema) {\n    return this._write(\"{\\n  \\\"schema\\\": \".concat(JSON.stringify({\n      fields: schema.fields.map(fieldToJSON)\n    }, null, 2)));\n  }\n  _writeDictionaries(batch) {\n    if (batch.dictionaries.size > 0) {\n      this._dictionaries.push(batch);\n    }\n    return this;\n  }\n  _writeDictionaryBatch(dictionary, id) {\n    let isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n    this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n    this._write(this._dictionaryBlocks.length === 0 ? \"    \" : \",\\n    \");\n    this._write(\"\".concat(dictionaryBatchToJSON(dictionary, id, isDelta)));\n    this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n    return this;\n  }\n  _writeRecordBatch(batch) {\n    this._writeDictionaries(batch);\n    this._recordBatches.push(batch);\n    return this;\n  }\n  close() {\n    if (this._dictionaries.length > 0) {\n      this._write(\",\\n  \\\"dictionaries\\\": [\\n\");\n      for (const batch of this._dictionaries) {\n        super._writeDictionaries(batch);\n      }\n      this._write(\"\\n  ]\");\n    }\n    if (this._recordBatches.length > 0) {\n      for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n        this._write(i === 0 ? \",\\n  \\\"batches\\\": [\\n    \" : \",\\n    \");\n        this._write(\"\".concat(recordBatchToJSON(this._recordBatches[i])));\n        this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n      }\n      this._write(\"\\n  ]\");\n    }\n    if (this._schema) {\n      this._write(\"\\n}\");\n    }\n    this._dictionaries = [];\n    this._recordBatches = [];\n    return super.close();\n  }\n}\n/** @ignore */\nfunction writeAll(writer, input) {\n  let chunks = input;\n  if (input instanceof Table) {\n    chunks = input.chunks;\n    writer.reset(undefined, input.schema);\n  }\n  for (const batch of chunks) {\n    writer.write(batch);\n  }\n  return writer.finish();\n}\n/** @ignore */\nasync function writeAllAsync(writer, batches) {\n  for await (const batch of batches) {\n    writer.write(batch);\n  }\n  return writer.finish();\n}\n/** @ignore */\nfunction fieldToJSON(_ref) {\n  let {\n    name,\n    type,\n    nullable\n  } = _ref;\n  const assembler = new JSONTypeAssembler();\n  return {\n    'name': name,\n    'nullable': nullable,\n    'type': assembler.visit(type),\n    'children': (type.children || []).map(fieldToJSON),\n    'dictionary': !DataType.isDictionary(type) ? undefined : {\n      'id': type.id,\n      'isOrdered': type.isOrdered,\n      'indexType': assembler.visit(type.indices)\n    }\n  };\n}\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary, id) {\n  let isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n  const field = new Field(\"\".concat(id), dictionary.type, dictionary.nullCount > 0);\n  const columns = JSONVectorAssembler.assemble(new Column(field, [dictionary]));\n  return JSON.stringify({\n    'id': id,\n    'isDelta': isDelta,\n    'data': {\n      'count': dictionary.length,\n      'columns': columns\n    }\n  }, null, 2);\n}\n/** @ignore */\nfunction recordBatchToJSON(records) {\n  return JSON.stringify({\n    'count': records.length,\n    'columns': JSONVectorAssembler.assemble(records)\n  }, null, 2);\n}","map":{"version":3,"names":["Table","MAGIC","Column","DataType","Field","Message","metadata","FileBlock","Footer","MessageHeader","MetadataVersion","AsyncByteQueue","VectorAssembler","JSONTypeAssembler","JSONVectorAssembler","toUint8Array","RecordBatch","_InternalEmptyPlaceholderRecordBatch","ReadableInterop","isPromise","isAsyncIterable","isWritableDOMStream","isWritableNodeStream","isIterable","isObject","RecordBatchWriter","constructor","options","_position","_started","_sink","_schema","_dictionaryBlocks","_recordBatchBlocks","_dictionaryDeltaOffsets","Map","autoDestroy","writeLegacyIpcFormat","_autoDestroy","_writeLegacyIpcFormat","throughNode","Error","throughDOM","writableStrategy","readableStrategy","toString","sync","arguments","length","undefined","writeAll","input","then","x","writeAllAsync","closed","Symbol","asyncIterator","toDOMStream","toNodeStream","close","reset","abort","reason","finish","sink","schema","type","pipeTo","objectMode","pipe","_writeFooter","compareTo","_writeSchema","write","payload","_writeRecordBatch","chunks","_writeMessage","message","alignment","a","buffer","encode","flatbufferSize","byteLength","prefixSize","alignedSize","nPaddingBytes","headerType","push","bodyLength","DictionaryBatch","_write","Int32Array","of","_writePadding","chunk","from","_writeMagic","nBytes","Uint8Array","batch","nodes","bufferRegions","buffers","assemble","recordBatch","_writeDictionaries","_writeBodyBuffers","_writeDictionaryBatch","dictionary","id","isDelta","set","get","dictionaryBatch","size","padding","i","n","dictionaries","offset","slice","RecordBatchStreamWriter","writer","RecordBatchFileWriter","V4","RecordBatchJSONWriter","_recordBatches","_dictionaries","concat","JSON","stringify","fields","map","fieldToJSON","dictionaryBatchToJSON","recordBatchToJSON","batches","_ref","name","nullable","assembler","visit","children","isDictionary","isOrdered","indices","field","nullCount","columns","records"],"sources":["ipc/writer.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Table } from '../table';\nimport { MAGIC } from './message';\nimport { Vector } from '../vector';\nimport { Column } from '../column';\nimport { DataType } from '../type';\nimport { Schema, Field } from '../schema';\nimport { Message } from './metadata/message';\nimport * as metadata from './metadata/message';\nimport { FileBlock, Footer } from './metadata/file';\nimport { MessageHeader, MetadataVersion } from '../enum';\nimport { WritableSink, AsyncByteQueue } from '../io/stream';\nimport { VectorAssembler } from '../visitor/vectorassembler';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler';\nimport { ArrayBufferViewInput, toUint8Array } from '../util/buffer';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch';\nimport { Writable, ReadableInterop, ReadableDOMStreamOptions } from '../io/interfaces';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat';\n\nexport interface RecordBatchStreamWriterOptions {\n    /**\n     *\n     */\n    autoDestroy?: boolean;\n    /**\n     * A flag indicating whether the RecordBatchWriter should construct pre-0.15.0\n     * encapsulated IPC Messages, which reserves  4 bytes for the Message metadata\n     * length instead of 8.\n     * @see https://issues.apache.org/jira/browse/ARROW-6313\n     */\n    writeLegacyIpcFormat?: boolean;\n}\n\nexport class RecordBatchWriter<T extends { [key: string]: DataType } = any> extends ReadableInterop<Uint8Array> implements Writable<RecordBatch<T>> {\n\n    /** @nocollapse */\n    // @ts-ignore\n    public static throughNode(options?: import('stream').DuplexOptions & { autoDestroy: boolean }): import('stream').Duplex {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    public static throughDOM<T extends { [key: string]: DataType }>(\n        // @ts-ignore\n        writableStrategy?: QueuingStrategy<RecordBatch<T>> & { autoDestroy: boolean },\n        // @ts-ignore\n        readableStrategy?: { highWaterMark?: number, size?: any }\n    ): { writable: WritableStream<Table<T> | RecordBatch<T>>, readable: ReadableStream<Uint8Array> } {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n\n    constructor(options?: RecordBatchStreamWriterOptions) {\n        super();\n        isObject(options) || (options = { autoDestroy: true, writeLegacyIpcFormat: false });\n        this._autoDestroy = (typeof options.autoDestroy === 'boolean') ? options.autoDestroy : true;\n        this._writeLegacyIpcFormat = (typeof options.writeLegacyIpcFormat === 'boolean') ? options.writeLegacyIpcFormat : false;\n    }\n\n    protected _position = 0;\n    protected _started = false;\n    protected _autoDestroy: boolean;\n    protected _writeLegacyIpcFormat: boolean;\n    // @ts-ignore\n    protected _sink = new AsyncByteQueue();\n    protected _schema: Schema | null = null;\n    protected _dictionaryBlocks: FileBlock[] = [];\n    protected _recordBatchBlocks: FileBlock[] = [];\n    protected _dictionaryDeltaOffsets = new Map<number, number>();\n\n    public toString(sync: true): string;\n    public toString(sync?: false): Promise<string>;\n    public toString(sync: any = false) {\n        return this._sink.toString(sync) as Promise<string> | string;\n    }\n    public toUint8Array(sync: true): Uint8Array;\n    public toUint8Array(sync?: false): Promise<Uint8Array>;\n    public toUint8Array(sync: any = false) {\n        return this._sink.toUint8Array(sync) as Promise<Uint8Array> | Uint8Array;\n    }\n\n    public writeAll(input: Table<T> | Iterable<RecordBatch<T>>): this;\n    public writeAll(input: AsyncIterable<RecordBatch<T>>): Promise<this>;\n    public writeAll(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<any> | Table<T> | Iterable<RecordBatch<T>> | AsyncIterable<RecordBatch<T>>) {\n        if (isPromise<any>(input)) {\n            return input.then((x) => this.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(this, input);\n        }\n        return writeAll(this, <any> input);\n    }\n\n    public get closed() { return this._sink.closed; }\n    public [Symbol.asyncIterator]() { return this._sink[Symbol.asyncIterator](); }\n    public toDOMStream(options?: ReadableDOMStreamOptions) { return this._sink.toDOMStream(options); }\n    public toNodeStream(options?: import('stream').ReadableOptions) { return this._sink.toNodeStream(options); }\n\n    public close() {\n        return this.reset()._sink.close();\n    }\n    public abort(reason?: any) {\n        return this.reset()._sink.abort(reason);\n    }\n    public finish() {\n        this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n        return this;\n    }\n    public reset(sink: WritableSink<ArrayBufferViewInput> = this._sink, schema: Schema<T> | null = null) {\n\n        if ((sink === this._sink) || (sink instanceof AsyncByteQueue)) {\n            this._sink = sink as AsyncByteQueue;\n        } else {\n            this._sink = new AsyncByteQueue();\n            if (sink && isWritableDOMStream(sink)) {\n                this.toDOMStream({ type: 'bytes' }).pipeTo(sink);\n            } else if (sink && isWritableNodeStream(sink)) {\n                this.toNodeStream({ objectMode: false }).pipe(sink);\n            }\n        }\n\n        if (this._started && this._schema) {\n            this._writeFooter(this._schema);\n        }\n\n        this._started = false;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n\n        if (!schema || !(schema.compareTo(this._schema))) {\n            if (schema === null) {\n                this._position = 0;\n                this._schema = null;\n            } else {\n                this._started = true;\n                this._schema = schema;\n                this._writeSchema(schema);\n            }\n        }\n\n        return this;\n    }\n\n    public write(payload?: Table<T> | RecordBatch<T> | Iterable<RecordBatch<T>> | null) {\n\n        let schema: Schema<T> | null = null;\n\n        if (!this._sink) {\n            throw new Error(`RecordBatchWriter is closed`);\n        } else if (payload === null || payload === undefined) {\n            return this.finish() && undefined;\n        } else if (payload instanceof Table && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n\n        if (schema && !schema.compareTo(this._schema)) {\n            if (this._started && this._autoDestroy) {\n                return this.close();\n            }\n            this.reset(this._sink, schema);\n        }\n\n        if (payload instanceof RecordBatch) {\n            if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n                this._writeRecordBatch(payload);\n            }\n        } else if (payload instanceof Table) {\n            this.writeAll(payload.chunks);\n        } else if (isIterable(payload)) {\n            this.writeAll(payload);\n        }\n    }\n\n    protected _writeMessage<T extends MessageHeader>(message: Message<T>, alignment = 8) {\n\n        const a = alignment - 1;\n        const buffer = Message.encode(message);\n        const flatbufferSize = buffer.byteLength;\n        const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n        const alignedSize = (flatbufferSize + prefixSize + a) & ~a;\n        const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n\n        if (message.headerType === MessageHeader.RecordBatch) {\n            this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        } else if (message.headerType === MessageHeader.DictionaryBatch) {\n            this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n\n        // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n        if (!this._writeLegacyIpcFormat) {\n            this._write(Int32Array.of(-1));\n        }\n        // Write the flatbuffer size prefix including padding\n        this._write(Int32Array.of(alignedSize - prefixSize));\n        // Write the flatbuffer\n        if (flatbufferSize > 0) { this._write(buffer); }\n        // Write any padding\n        return this._writePadding(nPaddingBytes);\n    }\n\n    protected _write(chunk: ArrayBufferViewInput) {\n        if (this._started) {\n            const buffer = toUint8Array(chunk);\n            if (buffer && buffer.byteLength > 0) {\n                this._sink.write(buffer);\n                this._position += buffer.byteLength;\n            }\n        }\n        return this;\n    }\n\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMessage(Message.from(schema));\n    }\n\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) {\n        // eos bytes\n        return this._writeLegacyIpcFormat\n            ? this._write(Int32Array.of(0))\n            : this._write(Int32Array.of(-1, 0));\n    }\n\n    protected _writeMagic() {\n        return this._write(MAGIC);\n    }\n\n    protected _writePadding(nBytes: number) {\n        return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(batch);\n        const recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n        const message = Message.from(recordBatch, byteLength);\n        return this\n            ._writeDictionaries(batch)\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeDictionaryBatch(dictionary: Vector, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(dictionary);\n        const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n        const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n        const message = Message.from(dictionaryBatch, byteLength);\n        return this\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeBodyBuffers(buffers: ArrayBufferView[]) {\n        let buffer: ArrayBufferView;\n        let size: number, padding: number;\n        for (let i = -1, n = buffers.length; ++i < n;) {\n            if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n                this._write(buffer);\n                if ((padding = ((size + 7) & ~7) - size) > 0) {\n                    this._writePadding(padding);\n                }\n            }\n        }\n        return this;\n    }\n\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        for (let [id, dictionary] of batch.dictionaries) {\n            let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n            if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n                const chunks = 'chunks' in dictionary ? (dictionary as any).chunks : [dictionary];\n                for (const chunk of chunks) {\n                    this._writeDictionaryBatch(chunk, id, offset > 0);\n                    offset += chunk.length;\n                }\n            }\n        }\n        return this;\n    }\n}\n\n/** @ignore */\nexport class RecordBatchStreamWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: Table<T> | Iterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): RecordBatchStreamWriter<T>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: AsyncIterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: any, options?: RecordBatchStreamWriterOptions) {\n        const writer = new RecordBatchStreamWriter<T>(options);\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n}\n\n/** @ignore */\nexport class RecordBatchFileWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchFileWriter<T>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: any) {\n        const writer = new RecordBatchFileWriter<T>();\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n    }\n\n    // @ts-ignore\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMagic()._writePadding(2);\n    }\n\n    protected _writeFooter(schema: Schema<T>) {\n        const buffer = Footer.encode(new Footer(\n            schema, MetadataVersion.V4,\n            this._recordBatchBlocks, this._dictionaryBlocks\n        ));\n        return super\n            ._writeFooter(schema) // EOS bytes for sequential readers\n            ._write(buffer) // Write the flatbuffer\n            ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n            ._writeMagic(); // then the magic suffix\n    }\n}\n\n/** @ignore */\nexport class RecordBatchJSONWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchJSONWriter<T>;\n    // @ts-ignore\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: any) {\n        return new RecordBatchJSONWriter<T>().writeAll(input as any);\n    }\n\n    private _recordBatches: RecordBatch[];\n    private _dictionaries: RecordBatch[];\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n        this._recordBatches = [];\n        this._dictionaries = [];\n    }\n\n    protected _writeMessage() { return this; }\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) { return this; }\n    protected _writeSchema(schema: Schema<T>) {\n        return this._write(`{\\n  \"schema\": ${\n            JSON.stringify({ fields: schema.fields.map(fieldToJSON) }, null, 2)\n        }`);\n    }\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        if (batch.dictionaries.size > 0) {\n            this._dictionaries.push(batch);\n        }\n        return this;\n    }\n    protected _writeDictionaryBatch(dictionary: Vector, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        this._write(this._dictionaryBlocks.length === 0 ? `    ` : `,\\n    `);\n        this._write(`${dictionaryBatchToJSON(dictionary, id, isDelta)}`);\n        this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n        return this;\n    }\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        this._writeDictionaries(batch);\n        this._recordBatches.push(batch);\n        return this;\n    }\n    public close() {\n\n        if (this._dictionaries.length > 0) {\n            this._write(`,\\n  \"dictionaries\": [\\n`);\n            for (const batch of this._dictionaries) {\n                super._writeDictionaries(batch);\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._recordBatches.length > 0) {\n            for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n                this._write(i === 0 ? `,\\n  \"batches\": [\\n    ` : `,\\n    `);\n                this._write(`${recordBatchToJSON(this._recordBatches[i])}`);\n                this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._schema) {\n            this._write(`\\n}`);\n        }\n\n        this._dictionaries = [];\n        this._recordBatches = [];\n\n        return super.close();\n    }\n}\n\n/** @ignore */\nfunction writeAll<T extends { [key: string]: DataType } = any>(writer: RecordBatchWriter<T>, input: Table<T> | Iterable<RecordBatch<T>>) {\n    let chunks = input as Iterable<RecordBatch<T>>;\n    if (input instanceof Table) {\n        chunks = input.chunks;\n        writer.reset(undefined, input.schema);\n    }\n    for (const batch of chunks) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nasync function writeAllAsync<T extends { [key: string]: DataType } = any>(writer: RecordBatchWriter<T>, batches: AsyncIterable<RecordBatch<T>>) {\n    for await (const batch of batches) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nfunction fieldToJSON({ name, type, nullable }: Field): object {\n    const assembler = new JSONTypeAssembler();\n    return {\n        'name': name, 'nullable': nullable,\n        'type': assembler.visit(type),\n        'children': (type.children || []).map(fieldToJSON),\n        'dictionary': !DataType.isDictionary(type) ? undefined : {\n            'id': type.id,\n            'isOrdered': type.isOrdered,\n            'indexType': assembler.visit(type.indices)\n        }\n    };\n}\n\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary: Vector, id: number, isDelta = false) {\n    const field = new Field(`${id}`, dictionary.type, dictionary.nullCount > 0);\n    const columns = JSONVectorAssembler.assemble(new Column(field, [dictionary]));\n    return JSON.stringify({\n        'id': id,\n        'isDelta': isDelta,\n        'data': {\n            'count': dictionary.length,\n            'columns': columns\n        }\n    }, null, 2);\n}\n\n/** @ignore */\nfunction recordBatchToJSON(records: RecordBatch) {\n    return JSON.stringify({\n        'count': records.length,\n        'columns': JSONVectorAssembler.assemble(records)\n    }, null, 2);\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAASA,KAAK,QAAQ,UAAU;AAChC,SAASC,KAAK,QAAQ,WAAW;AAEjC,SAASC,MAAM,QAAQ,WAAW;AAClC,SAASC,QAAQ,QAAQ,SAAS;AAClC,SAAiBC,KAAK,QAAQ,WAAW;AACzC,SAASC,OAAO,QAAQ,oBAAoB;AAC5C,OAAO,KAAKC,QAAQ,MAAM,oBAAoB;AAC9C,SAASC,SAAS,EAAEC,MAAM,QAAQ,iBAAiB;AACnD,SAASC,aAAa,EAAEC,eAAe,QAAQ,SAAS;AACxD,SAAuBC,cAAc,QAAQ,cAAc;AAC3D,SAASC,eAAe,QAAQ,4BAA4B;AAC5D,SAASC,iBAAiB,QAAQ,8BAA8B;AAChE,SAASC,mBAAmB,QAAQ,gCAAgC;AACpE,SAA+BC,YAAY,QAAQ,gBAAgB;AACnE,SAASC,WAAW,EAAEC,oCAAoC,QAAQ,gBAAgB;AAClF,SAAmBC,eAAe,QAAkC,kBAAkB;AACtF,SAASC,SAAS,EAAEC,eAAe,EAAEC,mBAAmB,EAAEC,oBAAoB,EAAEC,UAAU,EAAEC,QAAQ,QAAQ,gBAAgB;AAgB5H,OAAM,MAAOC,iBAA+D,SAAQP,eAA2B;EAiB3GQ,YAAYC,OAAwC;IAChD,KAAK,EAAE;IAMD,KAAAC,SAAS,GAAG,CAAC;IACb,KAAAC,QAAQ,GAAG,KAAK;IAG1B;IACU,KAAAC,KAAK,GAAG,IAAInB,cAAc,EAAE;IAC5B,KAAAoB,OAAO,GAAkB,IAAI;IAC7B,KAAAC,iBAAiB,GAAgB,EAAE;IACnC,KAAAC,kBAAkB,GAAgB,EAAE;IACpC,KAAAC,uBAAuB,GAAG,IAAIC,GAAG,EAAkB;IAdzDX,QAAQ,CAACG,OAAO,CAAC,KAAKA,OAAO,GAAG;MAAES,WAAW,EAAE,IAAI;MAAEC,oBAAoB,EAAE;IAAK,CAAE,CAAC;IACnF,IAAI,CAACC,YAAY,GAAI,OAAOX,OAAO,CAACS,WAAW,KAAK,SAAS,GAAIT,OAAO,CAACS,WAAW,GAAG,IAAI;IAC3F,IAAI,CAACG,qBAAqB,GAAI,OAAOZ,OAAO,CAACU,oBAAoB,KAAK,SAAS,GAAIV,OAAO,CAACU,oBAAoB,GAAG,KAAK;EAC3H;EApBA;EACA;EACO,OAAOG,WAAWA,CAACb,OAAmE;IACzF,MAAM,IAAIc,KAAK,oDAAkD,CAAC;EACtE;EACA;EACO,OAAOC,UAAUA;EACpB;EACAC,gBAA6E;EAC7E;EACAC,gBAAyD;IAEzD,MAAM,IAAIH,KAAK,mDAAiD,CAAC;EACrE;EAsBOI,QAAQA,CAAA,EAAkB;IAAA,IAAjBC,IAAA,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAY,KAAK;IAC7B,OAAO,IAAI,CAACjB,KAAK,CAACe,QAAQ,CAACC,IAAI,CAA6B;EAChE;EAGO/B,YAAYA,CAAA,EAAkB;IAAA,IAAjB+B,IAAA,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAY,KAAK;IACjC,OAAO,IAAI,CAACjB,KAAK,CAACf,YAAY,CAAC+B,IAAI,CAAqC;EAC5E;EAMOI,QAAQA,CAACC,KAA6F;IACzG,IAAIhC,SAAS,CAAMgC,KAAK,CAAC,EAAE;MACvB,OAAOA,KAAK,CAACC,IAAI,CAAEC,CAAC,IAAK,IAAI,CAACH,QAAQ,CAACG,CAAC,CAAC,CAAC;KAC7C,MAAM,IAAIjC,eAAe,CAAiB+B,KAAK,CAAC,EAAE;MAC/C,OAAOG,aAAa,CAAC,IAAI,EAAEH,KAAK,CAAC;;IAErC,OAAOD,QAAQ,CAAC,IAAI,EAAQC,KAAK,CAAC;EACtC;EAEA,IAAWI,MAAMA,CAAA;IAAK,OAAO,IAAI,CAACzB,KAAK,CAACyB,MAAM;EAAE;EACzC,CAACC,MAAM,CAACC,aAAa,IAAC;IAAK,OAAO,IAAI,CAAC3B,KAAK,CAAC0B,MAAM,CAACC,aAAa,CAAC,EAAE;EAAE;EACtEC,WAAWA,CAAC/B,OAAkC;IAAI,OAAO,IAAI,CAACG,KAAK,CAAC4B,WAAW,CAAC/B,OAAO,CAAC;EAAE;EAC1FgC,YAAYA,CAAChC,OAA0C;IAAI,OAAO,IAAI,CAACG,KAAK,CAAC6B,YAAY,CAAChC,OAAO,CAAC;EAAE;EAEpGiC,KAAKA,CAAA;IACR,OAAO,IAAI,CAACC,KAAK,EAAE,CAAC/B,KAAK,CAAC8B,KAAK,EAAE;EACrC;EACOE,KAAKA,CAACC,MAAY;IACrB,OAAO,IAAI,CAACF,KAAK,EAAE,CAAC/B,KAAK,CAACgC,KAAK,CAACC,MAAM,CAAC;EAC3C;EACOC,MAAMA,CAAA;IACT,IAAI,CAAC1B,YAAY,GAAG,IAAI,CAACsB,KAAK,EAAE,GAAG,IAAI,CAACC,KAAK,CAAC,IAAI,CAAC/B,KAAK,EAAE,IAAI,CAACC,OAAO,CAAC;IACvE,OAAO,IAAI;EACf;EACO8B,KAAKA,CAAA,EAAuF;IAAA,IAAtFI,IAAA,GAAAlB,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAA2C,IAAI,CAACjB,KAAK;IAAA,IAAEoC,MAAA,GAAAnB,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAA2B,IAAI;IAE/F,IAAKkB,IAAI,KAAK,IAAI,CAACnC,KAAK,IAAMmC,IAAI,YAAYtD,cAAe,EAAE;MAC3D,IAAI,CAACmB,KAAK,GAAGmC,IAAsB;KACtC,MAAM;MACH,IAAI,CAACnC,KAAK,GAAG,IAAInB,cAAc,EAAE;MACjC,IAAIsD,IAAI,IAAI5C,mBAAmB,CAAC4C,IAAI,CAAC,EAAE;QACnC,IAAI,CAACP,WAAW,CAAC;UAAES,IAAI,EAAE;QAAO,CAAE,CAAC,CAACC,MAAM,CAACH,IAAI,CAAC;OACnD,MAAM,IAAIA,IAAI,IAAI3C,oBAAoB,CAAC2C,IAAI,CAAC,EAAE;QAC3C,IAAI,CAACN,YAAY,CAAC;UAAEU,UAAU,EAAE;QAAK,CAAE,CAAC,CAACC,IAAI,CAACL,IAAI,CAAC;;;IAI3D,IAAI,IAAI,CAACpC,QAAQ,IAAI,IAAI,CAACE,OAAO,EAAE;MAC/B,IAAI,CAACwC,YAAY,CAAC,IAAI,CAACxC,OAAO,CAAC;;IAGnC,IAAI,CAACF,QAAQ,GAAG,KAAK;IACrB,IAAI,CAACG,iBAAiB,GAAG,EAAE;IAC3B,IAAI,CAACC,kBAAkB,GAAG,EAAE;IAC5B,IAAI,CAACC,uBAAuB,GAAG,IAAIC,GAAG,EAAE;IAExC,IAAI,CAAC+B,MAAM,IAAI,CAAEA,MAAM,CAACM,SAAS,CAAC,IAAI,CAACzC,OAAO,CAAE,EAAE;MAC9C,IAAImC,MAAM,KAAK,IAAI,EAAE;QACjB,IAAI,CAACtC,SAAS,GAAG,CAAC;QAClB,IAAI,CAACG,OAAO,GAAG,IAAI;OACtB,MAAM;QACH,IAAI,CAACF,QAAQ,GAAG,IAAI;QACpB,IAAI,CAACE,OAAO,GAAGmC,MAAM;QACrB,IAAI,CAACO,YAAY,CAACP,MAAM,CAAC;;;IAIjC,OAAO,IAAI;EACf;EAEOQ,KAAKA,CAACC,OAAqE;IAE9E,IAAIT,MAAM,GAAqB,IAAI;IAEnC,IAAI,CAAC,IAAI,CAACpC,KAAK,EAAE;MACb,MAAM,IAAIW,KAAK,8BAA8B,CAAC;KACjD,MAAM,IAAIkC,OAAO,KAAK,IAAI,IAAIA,OAAO,KAAK1B,SAAS,EAAE;MAClD,OAAO,IAAI,CAACe,MAAM,EAAE,IAAIf,SAAS;KACpC,MAAM,IAAI0B,OAAO,YAAY3E,KAAK,IAAI,EAAEkE,MAAM,GAAGS,OAAO,CAACT,MAAM,CAAC,EAAE;MAC/D,OAAO,IAAI,CAACF,MAAM,EAAE,IAAIf,SAAS;KACpC,MAAM,IAAI0B,OAAO,YAAY3D,WAAW,IAAI,EAAEkD,MAAM,GAAGS,OAAO,CAACT,MAAM,CAAC,EAAE;MACrE,OAAO,IAAI,CAACF,MAAM,EAAE,IAAIf,SAAS;;IAGrC,IAAIiB,MAAM,IAAI,CAACA,MAAM,CAACM,SAAS,CAAC,IAAI,CAACzC,OAAO,CAAC,EAAE;MAC3C,IAAI,IAAI,CAACF,QAAQ,IAAI,IAAI,CAACS,YAAY,EAAE;QACpC,OAAO,IAAI,CAACsB,KAAK,EAAE;;MAEvB,IAAI,CAACC,KAAK,CAAC,IAAI,CAAC/B,KAAK,EAAEoC,MAAM,CAAC;;IAGlC,IAAIS,OAAO,YAAY3D,WAAW,EAAE;MAChC,IAAI,EAAE2D,OAAO,YAAY1D,oCAAoC,CAAC,EAAE;QAC5D,IAAI,CAAC2D,iBAAiB,CAACD,OAAO,CAAC;;KAEtC,MAAM,IAAIA,OAAO,YAAY3E,KAAK,EAAE;MACjC,IAAI,CAACkD,QAAQ,CAACyB,OAAO,CAACE,MAAM,CAAC;KAChC,MAAM,IAAItD,UAAU,CAACoD,OAAO,CAAC,EAAE;MAC5B,IAAI,CAACzB,QAAQ,CAACyB,OAAO,CAAC;;EAE9B;EAEUG,aAAaA,CAA0BC,OAAmB,EAAe;IAAA,IAAbC,SAAS,GAAAjC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC;IAE/E,MAAMkC,CAAC,GAAGD,SAAS,GAAG,CAAC;IACvB,MAAME,MAAM,GAAG7E,OAAO,CAAC8E,MAAM,CAACJ,OAAO,CAAC;IACtC,MAAMK,cAAc,GAAGF,MAAM,CAACG,UAAU;IACxC,MAAMC,UAAU,GAAG,CAAC,IAAI,CAAC/C,qBAAqB,GAAG,CAAC,GAAG,CAAC;IACtD,MAAMgD,WAAW,GAAIH,cAAc,GAAGE,UAAU,GAAGL,CAAC,GAAI,CAACA,CAAC;IAC1D,MAAMO,aAAa,GAAGD,WAAW,GAAGH,cAAc,GAAGE,UAAU;IAE/D,IAAIP,OAAO,CAACU,UAAU,KAAKhF,aAAa,CAACO,WAAW,EAAE;MAClD,IAAI,CAACiB,kBAAkB,CAACyD,IAAI,CAAC,IAAInF,SAAS,CAACgF,WAAW,EAAER,OAAO,CAACY,UAAU,EAAE,IAAI,CAAC/D,SAAS,CAAC,CAAC;KAC/F,MAAM,IAAImD,OAAO,CAACU,UAAU,KAAKhF,aAAa,CAACmF,eAAe,EAAE;MAC7D,IAAI,CAAC5D,iBAAiB,CAAC0D,IAAI,CAAC,IAAInF,SAAS,CAACgF,WAAW,EAAER,OAAO,CAACY,UAAU,EAAE,IAAI,CAAC/D,SAAS,CAAC,CAAC;;IAG/F;IACA,IAAI,CAAC,IAAI,CAACW,qBAAqB,EAAE;MAC7B,IAAI,CAACsD,MAAM,CAACC,UAAU,CAACC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;;IAElC;IACA,IAAI,CAACF,MAAM,CAACC,UAAU,CAACC,EAAE,CAACR,WAAW,GAAGD,UAAU,CAAC,CAAC;IACpD;IACA,IAAIF,cAAc,GAAG,CAAC,EAAE;MAAE,IAAI,CAACS,MAAM,CAACX,MAAM,CAAC;;IAC7C;IACA,OAAO,IAAI,CAACc,aAAa,CAACR,aAAa,CAAC;EAC5C;EAEUK,MAAMA,CAACI,KAA2B;IACxC,IAAI,IAAI,CAACpE,QAAQ,EAAE;MACf,MAAMqD,MAAM,GAAGnE,YAAY,CAACkF,KAAK,CAAC;MAClC,IAAIf,MAAM,IAAIA,MAAM,CAACG,UAAU,GAAG,CAAC,EAAE;QACjC,IAAI,CAACvD,KAAK,CAAC4C,KAAK,CAACQ,MAAM,CAAC;QACxB,IAAI,CAACtD,SAAS,IAAIsD,MAAM,CAACG,UAAU;;;IAG3C,OAAO,IAAI;EACf;EAEUZ,YAAYA,CAACP,MAAiB;IACpC,OAAO,IAAI,CAACY,aAAa,CAACzE,OAAO,CAAC6F,IAAI,CAAChC,MAAM,CAAC,CAAC;EACnD;EAEA;EACUK,YAAYA,CAACL,MAAiB;IACpC;IACA,OAAO,IAAI,CAAC3B,qBAAqB,GAC3B,IAAI,CAACsD,MAAM,CAACC,UAAU,CAACC,EAAE,CAAC,CAAC,CAAC,CAAC,GAC7B,IAAI,CAACF,MAAM,CAACC,UAAU,CAACC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;EAC3C;EAEUI,WAAWA,CAAA;IACjB,OAAO,IAAI,CAACN,MAAM,CAAC5F,KAAK,CAAC;EAC7B;EAEU+F,aAAaA,CAACI,MAAc;IAClC,OAAOA,MAAM,GAAG,CAAC,GAAG,IAAI,CAACP,MAAM,CAAC,IAAIQ,UAAU,CAACD,MAAM,CAAC,CAAC,GAAG,IAAI;EAClE;EAEUxB,iBAAiBA,CAAC0B,KAAqB;IAC7C,MAAM;MAAEjB,UAAU;MAAEkB,KAAK;MAAEC,aAAa;MAAEC;IAAO,CAAE,GAAG7F,eAAe,CAAC8F,QAAQ,CAACJ,KAAK,CAAC;IACrF,MAAMK,WAAW,GAAG,IAAIrG,QAAQ,CAACU,WAAW,CAACsF,KAAK,CAACtD,MAAM,EAAEuD,KAAK,EAAEC,aAAa,CAAC;IAChF,MAAMzB,OAAO,GAAG1E,OAAO,CAAC6F,IAAI,CAACS,WAAW,EAAEtB,UAAU,CAAC;IACrD,OAAO,IAAI,CACNuB,kBAAkB,CAACN,KAAK,CAAC,CACzBxB,aAAa,CAACC,OAAO,CAAC,CACtB8B,iBAAiB,CAACJ,OAAO,CAAC;EACnC;EAEUK,qBAAqBA,CAACC,UAAkB,EAAEC,EAAU,EAAiB;IAAA,IAAfC,OAAO,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;IAC3E,IAAI,CAACb,uBAAuB,CAACgF,GAAG,CAACF,EAAE,EAAED,UAAU,CAAC/D,MAAM,IAAI,IAAI,CAACd,uBAAuB,CAACiF,GAAG,CAACH,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC;IACrG,MAAM;MAAE3B,UAAU;MAAEkB,KAAK;MAAEC,aAAa;MAAEC;IAAO,CAAE,GAAG7F,eAAe,CAAC8F,QAAQ,CAACK,UAAU,CAAC;IAC1F,MAAMJ,WAAW,GAAG,IAAIrG,QAAQ,CAACU,WAAW,CAAC+F,UAAU,CAAC/D,MAAM,EAAEuD,KAAK,EAAEC,aAAa,CAAC;IACrF,MAAMY,eAAe,GAAG,IAAI9G,QAAQ,CAACsF,eAAe,CAACe,WAAW,EAAEK,EAAE,EAAEC,OAAO,CAAC;IAC9E,MAAMlC,OAAO,GAAG1E,OAAO,CAAC6F,IAAI,CAACkB,eAAe,EAAE/B,UAAU,CAAC;IACzD,OAAO,IAAI,CACNP,aAAa,CAACC,OAAO,CAAC,CACtB8B,iBAAiB,CAACJ,OAAO,CAAC;EACnC;EAEUI,iBAAiBA,CAACJ,OAA0B;IAClD,IAAIvB,MAAuB;IAC3B,IAAImC,IAAY,EAAEC,OAAe;IACjC,KAAK,IAAIC,CAAC,GAAG,CAAC,CAAC,EAAEC,CAAC,GAAGf,OAAO,CAACzD,MAAM,EAAE,EAAEuE,CAAC,GAAGC,CAAC,GAAG;MAC3C,IAAI,CAACtC,MAAM,GAAGuB,OAAO,CAACc,CAAC,CAAC,KAAK,CAACF,IAAI,GAAGnC,MAAM,CAACG,UAAU,IAAI,CAAC,EAAE;QACzD,IAAI,CAACQ,MAAM,CAACX,MAAM,CAAC;QACnB,IAAI,CAACoC,OAAO,GAAG,CAAED,IAAI,GAAG,CAAC,GAAI,CAAC,CAAC,IAAIA,IAAI,IAAI,CAAC,EAAE;UAC1C,IAAI,CAACrB,aAAa,CAACsB,OAAO,CAAC;;;;IAIvC,OAAO,IAAI;EACf;EAEUV,kBAAkBA,CAACN,KAAqB;IAC9C,KAAK,IAAI,CAACU,EAAE,EAAED,UAAU,CAAC,IAAIT,KAAK,CAACmB,YAAY,EAAE;MAC7C,IAAIC,MAAM,GAAG,IAAI,CAACxF,uBAAuB,CAACiF,GAAG,CAACH,EAAE,CAAC,IAAI,CAAC;MACtD,IAAIU,MAAM,KAAK,CAAC,IAAI,CAACX,UAAU,GAAGA,UAAU,CAACY,KAAK,CAACD,MAAM,CAAC,EAAE1E,MAAM,GAAG,CAAC,EAAE;QACpE,MAAM6B,MAAM,GAAG,QAAQ,IAAIkC,UAAU,GAAIA,UAAkB,CAAClC,MAAM,GAAG,CAACkC,UAAU,CAAC;QACjF,KAAK,MAAMd,KAAK,IAAIpB,MAAM,EAAE;UACxB,IAAI,CAACiC,qBAAqB,CAACb,KAAK,EAAEe,EAAE,EAAEU,MAAM,GAAG,CAAC,CAAC;UACjDA,MAAM,IAAIzB,KAAK,CAACjD,MAAM;;;;IAIlC,OAAO,IAAI;EACf;;AAGJ;AACA,OAAM,MAAO4E,uBAAqE,SAAQnG,iBAAoB;EAK1G;EACO,OAAOyB,QAAQA,CAA8CC,KAAU,EAAExB,OAAwC;IACpH,MAAMkG,MAAM,GAAG,IAAID,uBAAuB,CAAIjG,OAAO,CAAC;IACtD,IAAIR,SAAS,CAAMgC,KAAK,CAAC,EAAE;MACvB,OAAOA,KAAK,CAACC,IAAI,CAAEC,CAAC,IAAKwE,MAAM,CAAC3E,QAAQ,CAACG,CAAC,CAAC,CAAC;KAC/C,MAAM,IAAIjC,eAAe,CAAiB+B,KAAK,CAAC,EAAE;MAC/C,OAAOG,aAAa,CAACuE,MAAM,EAAE1E,KAAK,CAAC;;IAEvC,OAAOD,QAAQ,CAAC2E,MAAM,EAAE1E,KAAK,CAAC;EAClC;;AAGJ;AACA,OAAM,MAAO2E,qBAAmE,SAAQrG,iBAAoB;EAgBxGC,YAAA;IACI,KAAK,EAAE;IACP,IAAI,CAACY,YAAY,GAAG,IAAI;EAC5B;EAdA;EACO,OAAOY,QAAQA,CAA8CC,KAAU;IAC1E,MAAM0E,MAAM,GAAG,IAAIC,qBAAqB,EAAK;IAC7C,IAAI3G,SAAS,CAAMgC,KAAK,CAAC,EAAE;MACvB,OAAOA,KAAK,CAACC,IAAI,CAAEC,CAAC,IAAKwE,MAAM,CAAC3E,QAAQ,CAACG,CAAC,CAAC,CAAC;KAC/C,MAAM,IAAIjC,eAAe,CAAiB+B,KAAK,CAAC,EAAE;MAC/C,OAAOG,aAAa,CAACuE,MAAM,EAAE1E,KAAK,CAAC;;IAEvC,OAAOD,QAAQ,CAAC2E,MAAM,EAAE1E,KAAK,CAAC;EAClC;EAOA;EACUsB,YAAYA,CAACP,MAAiB;IACpC,OAAO,IAAI,CAACiC,WAAW,EAAE,CAACH,aAAa,CAAC,CAAC,CAAC;EAC9C;EAEUzB,YAAYA,CAACL,MAAiB;IACpC,MAAMgB,MAAM,GAAG1E,MAAM,CAAC2E,MAAM,CAAC,IAAI3E,MAAM,CACnC0D,MAAM,EAAExD,eAAe,CAACqH,EAAE,EAC1B,IAAI,CAAC9F,kBAAkB,EAAE,IAAI,CAACD,iBAAiB,CAClD,CAAC;IACF,OAAO,KAAK,CACPuC,YAAY,CAACL,MAAM,CAAC,CAAC;IAAA,CACrB2B,MAAM,CAACX,MAAM,CAAC,CAAC;IAAA,CACfW,MAAM,CAACC,UAAU,CAACC,EAAE,CAACb,MAAM,CAACG,UAAU,CAAC,CAAC,CAAC;IAAA,CACzCc,WAAW,EAAE,CAAC,CAAC;EACxB;;AAGJ;AACA,OAAM,MAAO6B,qBAAmE,SAAQvG,iBAAoB;EAexGC,YAAA;IACI,KAAK,EAAE;IACP,IAAI,CAACY,YAAY,GAAG,IAAI;IACxB,IAAI,CAAC2F,cAAc,GAAG,EAAE;IACxB,IAAI,CAACC,aAAa,GAAG,EAAE;EAC3B;EAbA;EACO,OAAOhF,QAAQA,CAA8EC,KAAU;IAC1G,OAAO,IAAI6E,qBAAqB,EAAK,CAAC9E,QAAQ,CAACC,KAAY,CAAC;EAChE;EAYU2B,aAAaA,CAAA;IAAK,OAAO,IAAI;EAAE;EACzC;EACUP,YAAYA,CAACL,MAAiB;IAAI,OAAO,IAAI;EAAE;EAC/CO,YAAYA,CAACP,MAAiB;IACpC,OAAO,IAAI,CAAC2B,MAAM,qBAAAsC,MAAA,CACdC,IAAI,CAACC,SAAS,CAAC;MAAEC,MAAM,EAAEpE,MAAM,CAACoE,MAAM,CAACC,GAAG,CAACC,WAAW;IAAC,CAAE,EAAE,IAAI,EAAE,CAAC,CACtE,CAAE,CAAC;EACP;EACU5B,kBAAkBA,CAACN,KAAqB;IAC9C,IAAIA,KAAK,CAACmB,YAAY,CAACJ,IAAI,GAAG,CAAC,EAAE;MAC7B,IAAI,CAACa,aAAa,CAACxC,IAAI,CAACY,KAAK,CAAC;;IAElC,OAAO,IAAI;EACf;EACUQ,qBAAqBA,CAACC,UAAkB,EAAEC,EAAU,EAAiB;IAAA,IAAfC,OAAO,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;IAC3E,IAAI,CAACb,uBAAuB,CAACgF,GAAG,CAACF,EAAE,EAAED,UAAU,CAAC/D,MAAM,IAAI,IAAI,CAACd,uBAAuB,CAACiF,GAAG,CAACH,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC;IACrG,IAAI,CAACnB,MAAM,CAAC,IAAI,CAAC7D,iBAAiB,CAACgB,MAAM,KAAK,CAAC,qBAAqB,CAAC;IACrE,IAAI,CAAC6C,MAAM,IAAAsC,MAAA,CAAIM,qBAAqB,CAAC1B,UAAU,EAAEC,EAAE,EAAEC,OAAO,CAAC,CAAE,CAAC;IAChE,IAAI,CAACjF,iBAAiB,CAAC0D,IAAI,CAAC,IAAInF,SAAS,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;IACnD,OAAO,IAAI;EACf;EACUqE,iBAAiBA,CAAC0B,KAAqB;IAC7C,IAAI,CAACM,kBAAkB,CAACN,KAAK,CAAC;IAC9B,IAAI,CAAC2B,cAAc,CAACvC,IAAI,CAACY,KAAK,CAAC;IAC/B,OAAO,IAAI;EACf;EACO1C,KAAKA,CAAA;IAER,IAAI,IAAI,CAACsE,aAAa,CAAClF,MAAM,GAAG,CAAC,EAAE;MAC/B,IAAI,CAAC6C,MAAM,6BAA2B,CAAC;MACvC,KAAK,MAAMS,KAAK,IAAI,IAAI,CAAC4B,aAAa,EAAE;QACpC,KAAK,CAACtB,kBAAkB,CAACN,KAAK,CAAC;;MAEnC,IAAI,CAACT,MAAM,QAAQ,CAAC;;IAGxB,IAAI,IAAI,CAACoC,cAAc,CAACjF,MAAM,GAAG,CAAC,EAAE;MAChC,KAAK,IAAIuE,CAAC,GAAG,CAAC,CAAC,EAAEC,CAAC,GAAG,IAAI,CAACS,cAAc,CAACjF,MAAM,EAAE,EAAEuE,CAAC,GAAGC,CAAC,GAAG;QACvD,IAAI,CAAC3B,MAAM,CAAC0B,CAAC,KAAK,CAAC,0CAAwC,CAAC;QAC5D,IAAI,CAAC1B,MAAM,IAAAsC,MAAA,CAAIO,iBAAiB,CAAC,IAAI,CAACT,cAAc,CAACV,CAAC,CAAC,CAAC,CAAE,CAAC;QAC3D,IAAI,CAACtF,kBAAkB,CAACyD,IAAI,CAAC,IAAInF,SAAS,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;;MAExD,IAAI,CAACsF,MAAM,QAAQ,CAAC;;IAGxB,IAAI,IAAI,CAAC9D,OAAO,EAAE;MACd,IAAI,CAAC8D,MAAM,MAAM,CAAC;;IAGtB,IAAI,CAACqC,aAAa,GAAG,EAAE;IACvB,IAAI,CAACD,cAAc,GAAG,EAAE;IAExB,OAAO,KAAK,CAACrE,KAAK,EAAE;EACxB;;AAGJ;AACA,SAASV,QAAQA,CAA8C2E,MAA4B,EAAE1E,KAA0C;EACnI,IAAI0B,MAAM,GAAG1B,KAAiC;EAC9C,IAAIA,KAAK,YAAYnD,KAAK,EAAE;IACxB6E,MAAM,GAAG1B,KAAK,CAAC0B,MAAM;IACrBgD,MAAM,CAAChE,KAAK,CAACZ,SAAS,EAAEE,KAAK,CAACe,MAAM,CAAC;;EAEzC,KAAK,MAAMoC,KAAK,IAAIzB,MAAM,EAAE;IACxBgD,MAAM,CAACnD,KAAK,CAAC4B,KAAK,CAAC;;EAEvB,OAAOuB,MAAM,CAAC7D,MAAM,EAAE;AAC1B;AAEA;AACA,eAAeV,aAAaA,CAA8CuE,MAA4B,EAAEc,OAAsC;EAC1I,WAAW,MAAMrC,KAAK,IAAIqC,OAAO,EAAE;IAC/Bd,MAAM,CAACnD,KAAK,CAAC4B,KAAK,CAAC;;EAEvB,OAAOuB,MAAM,CAAC7D,MAAM,EAAE;AAC1B;AAEA;AACA,SAASwE,WAAWA,CAAAI,IAAA,EAAgC;EAAA,IAA/B;IAAEC,IAAI;IAAE1E,IAAI;IAAE2E;EAAQ,CAAS,GAAAF,IAAA;EAChD,MAAMG,SAAS,GAAG,IAAIlI,iBAAiB,EAAE;EACzC,OAAO;IACH,MAAM,EAAEgI,IAAI;IAAE,UAAU,EAAEC,QAAQ;IAClC,MAAM,EAAEC,SAAS,CAACC,KAAK,CAAC7E,IAAI,CAAC;IAC7B,UAAU,EAAE,CAACA,IAAI,CAAC8E,QAAQ,IAAI,EAAE,EAAEV,GAAG,CAACC,WAAW,CAAC;IAClD,YAAY,EAAE,CAACrI,QAAQ,CAAC+I,YAAY,CAAC/E,IAAI,CAAC,GAAGlB,SAAS,GAAG;MACrD,IAAI,EAAEkB,IAAI,CAAC6C,EAAE;MACb,WAAW,EAAE7C,IAAI,CAACgF,SAAS;MAC3B,WAAW,EAAEJ,SAAS,CAACC,KAAK,CAAC7E,IAAI,CAACiF,OAAO;;GAEhD;AACL;AAEA;AACA,SAASX,qBAAqBA,CAAC1B,UAAkB,EAAEC,EAAU,EAAiB;EAAA,IAAfC,OAAO,GAAAlE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAC1E,MAAMsG,KAAK,GAAG,IAAIjJ,KAAK,IAAA+H,MAAA,CAAInB,EAAE,GAAID,UAAU,CAAC5C,IAAI,EAAE4C,UAAU,CAACuC,SAAS,GAAG,CAAC,CAAC;EAC3E,MAAMC,OAAO,GAAGzI,mBAAmB,CAAC4F,QAAQ,CAAC,IAAIxG,MAAM,CAACmJ,KAAK,EAAE,CAACtC,UAAU,CAAC,CAAC,CAAC;EAC7E,OAAOqB,IAAI,CAACC,SAAS,CAAC;IAClB,IAAI,EAAErB,EAAE;IACR,SAAS,EAAEC,OAAO;IAClB,MAAM,EAAE;MACJ,OAAO,EAAEF,UAAU,CAAC/D,MAAM;MAC1B,SAAS,EAAEuG;;GAElB,EAAE,IAAI,EAAE,CAAC,CAAC;AACf;AAEA;AACA,SAASb,iBAAiBA,CAACc,OAAoB;EAC3C,OAAOpB,IAAI,CAACC,SAAS,CAAC;IAClB,OAAO,EAAEmB,OAAO,CAACxG,MAAM;IACvB,SAAS,EAAElC,mBAAmB,CAAC4F,QAAQ,CAAC8C,OAAO;GAClD,EAAE,IAAI,EAAE,CAAC,CAAC;AACf","ignoreList":[]},"metadata":{},"sourceType":"module"}