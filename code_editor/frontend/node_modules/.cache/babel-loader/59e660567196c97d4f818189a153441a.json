{"ast":null,"code":"// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Schema, Field } from '../../schema';\nimport { Dictionary, Utf8, Binary, Decimal, FixedSizeBinary, List, FixedSizeList, Map_, Struct, Union, Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, Int32 } from '../../type';\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n/** @ignore */\nexport function schemaFromJSON(_schema) {\n  let dictionaries = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : new Map();\n  return new Schema(schemaFieldsFromJSON(_schema, dictionaries), customMetadataFromJSON(_schema['customMetadata']), dictionaries);\n}\n/** @ignore */\nexport function recordBatchFromJSON(b) {\n  return new RecordBatch(b['count'], fieldNodesFromJSON(b['columns']), buffersFromJSON(b['columns']));\n}\n/** @ignore */\nexport function dictionaryBatchFromJSON(b) {\n  return new DictionaryBatch(recordBatchFromJSON(b['data']), b['id'], b['isDelta']);\n}\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema, dictionaries) {\n  return (_schema['fields'] || []).filter(Boolean).map(f => Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\nfunction fieldChildrenFromJSON(_field, dictionaries) {\n  return (_field['children'] || []).filter(Boolean).map(f => Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\nfunction fieldNodesFromJSON(xs) {\n  return (xs || []).reduce((fieldNodes, column) => [...fieldNodes, new FieldNode(column['count'], nullCountFromJSON(column['VALIDITY'])), ...fieldNodesFromJSON(column['children'])], []);\n}\n/** @ignore */\nfunction buffersFromJSON(xs) {\n  let buffers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n  for (let i = -1, n = (xs || []).length; ++i < n;) {\n    const column = xs[i];\n    column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n    column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n    column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n    column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n    buffers = buffersFromJSON(column['children'], buffers);\n  }\n  return buffers;\n}\n/** @ignore */\nfunction nullCountFromJSON(validity) {\n  return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n/** @ignore */\nexport function fieldFromJSON(_field, dictionaries) {\n  let id;\n  let keys;\n  let field;\n  let dictMeta;\n  let type;\n  let dictType;\n  // If no dictionary encoding\n  if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n    type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n    field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  // tslint:disable\n  // If dictionary encoded and the first time we've seen this dictionary id, decode\n  // the data type and child fields, then wrap in a Dictionary type and insert the\n  // data type into the dictionary types map.\n  else if (!dictionaries.has(id = dictMeta['id'])) {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n    dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n  // data type and wrap in a new Dictionary type and field.\n  else {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictType = new Dictionary(dictionaries.get(id), keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  return field || null;\n}\n/** @ignore */\nfunction customMetadataFromJSON(_metadata) {\n  return new Map(Object.entries(_metadata || {}));\n}\n/** @ignore */\nfunction indexTypeFromJSON(_type) {\n  return new Int(_type['isSigned'], _type['bitWidth']);\n}\n/** @ignore */\nfunction typeFromJSON(f, children) {\n  const typeId = f['type']['name'];\n  switch (typeId) {\n    case 'NONE':\n      return new Null();\n    case 'null':\n      return new Null();\n    case 'binary':\n      return new Binary();\n    case 'utf8':\n      return new Utf8();\n    case 'bool':\n      return new Bool();\n    case 'list':\n      return new List((children || [])[0]);\n    case 'struct':\n      return new Struct(children || []);\n    case 'struct_':\n      return new Struct(children || []);\n  }\n  switch (typeId) {\n    case 'int':\n      {\n        const t = f['type'];\n        return new Int(t['isSigned'], t['bitWidth']);\n      }\n    case 'floatingpoint':\n      {\n        const t = f['type'];\n        return new Float(Precision[t['precision']]);\n      }\n    case 'decimal':\n      {\n        const t = f['type'];\n        return new Decimal(t['scale'], t['precision']);\n      }\n    case 'date':\n      {\n        const t = f['type'];\n        return new Date_(DateUnit[t['unit']]);\n      }\n    case 'time':\n      {\n        const t = f['type'];\n        return new Time(TimeUnit[t['unit']], t['bitWidth']);\n      }\n    case 'timestamp':\n      {\n        const t = f['type'];\n        return new Timestamp(TimeUnit[t['unit']], t['timezone']);\n      }\n    case 'interval':\n      {\n        const t = f['type'];\n        return new Interval(IntervalUnit[t['unit']]);\n      }\n    case 'union':\n      {\n        const t = f['type'];\n        return new Union(UnionMode[t['mode']], t['typeIds'] || [], children || []);\n      }\n    case 'fixedsizebinary':\n      {\n        const t = f['type'];\n        return new FixedSizeBinary(t['byteWidth']);\n      }\n    case 'fixedsizelist':\n      {\n        const t = f['type'];\n        return new FixedSizeList(t['listSize'], (children || [])[0]);\n      }\n    case 'map':\n      {\n        const t = f['type'];\n        return new Map_((children || [])[0], t['keysSorted']);\n      }\n  }\n  throw new Error(`Unrecognized type: \"${typeId}\"`);\n}","map":{"version":3,"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAASA,MAAM,EAAEC,KAAK,QAAQ,cAAc;AAC5C,SACcC,UAAU,EACpBC,IAAI,EAAEC,MAAM,EAAEC,OAAO,EAAEC,eAAe,EACtCC,IAAI,EAAEC,aAAa,EAAEC,IAAI,EAAEC,MAAM,EAAEC,KAAK,EACxCC,IAAI,EAAEC,IAAI,EAAEC,GAAG,EAAEC,KAAK,EAAEC,KAAK,EAAEC,IAAI,EAAEC,QAAQ,EAAEC,SAAS,EAAeC,KAAK,QACzE,YAAY;AAEnB,SAASC,eAAe,EAAEC,WAAW,EAAEC,SAAS,EAAEC,YAAY,QAAQ,WAAW;AACjF,SAASC,QAAQ,EAAEC,SAAS,EAAEC,YAAY,EAAEC,SAAS,EAAEC,QAAQ,QAAQ,YAAY;AAEnF;AACA,OAAM,SAAUC,cAAc,CAACC,OAAY,EAAiD;EAAA,IAA/CC,mFAAsC,IAAIC,GAAG,EAAE;EACxF,OAAO,IAAIjC,MAAM,CACbkC,oBAAoB,CAACH,OAAO,EAAEC,YAAY,CAAC,EAC3CG,sBAAsB,CAACJ,OAAO,CAAC,gBAAgB,CAAC,CAAC,EACjDC,YAAY,CACf;AACL;AAEA;AACA,OAAM,SAAUI,mBAAmB,CAACC,CAAM;EACtC,OAAO,IAAIf,WAAW,CAClBe,CAAC,CAAC,OAAO,CAAC,EACVC,kBAAkB,CAACD,CAAC,CAAC,SAAS,CAAC,CAAC,EAChCE,eAAe,CAACF,CAAC,CAAC,SAAS,CAAC,CAAC,CAChC;AACL;AAEA;AACA,OAAM,SAAUG,uBAAuB,CAACH,CAAM;EAC1C,OAAO,IAAIhB,eAAe,CACtBe,mBAAmB,CAACC,CAAC,CAAC,MAAM,CAAC,CAAC,EAC9BA,CAAC,CAAC,IAAI,CAAC,EAAEA,CAAC,CAAC,SAAS,CAAC,CACxB;AACL;AAEA;AACA,SAASH,oBAAoB,CAACH,OAAY,EAAEC,YAAoC;EAC5E,OAAO,CAACD,OAAO,CAAC,QAAQ,CAAC,IAAI,EAAE,EAAEU,MAAM,CAACC,OAAO,CAAC,CAACC,GAAG,CAAEC,CAAM,IAAK3C,KAAK,CAAC4C,QAAQ,CAACD,CAAC,EAAEZ,YAAY,CAAC,CAAC;AACrG;AAEA;AACA,SAASc,qBAAqB,CAACC,MAAW,EAAEf,YAAoC;EAC5E,OAAO,CAACe,MAAM,CAAC,UAAU,CAAC,IAAI,EAAE,EAAEN,MAAM,CAACC,OAAO,CAAC,CAACC,GAAG,CAAEC,CAAM,IAAK3C,KAAK,CAAC4C,QAAQ,CAACD,CAAC,EAAEZ,YAAY,CAAC,CAAC;AACtG;AAEA;AACA,SAASM,kBAAkB,CAACU,EAAS;EACjC,OAAO,CAACA,EAAE,IAAI,EAAE,EAAEC,MAAM,CAAc,CAACC,UAAU,EAAEC,MAAW,KAAK,CAC/D,GAAGD,UAAU,EACb,IAAI3B,SAAS,CACT4B,MAAM,CAAC,OAAO,CAAC,EACfC,iBAAiB,CAACD,MAAM,CAAC,UAAU,CAAC,CAAC,CACxC,EACD,GAAGb,kBAAkB,CAACa,MAAM,CAAC,UAAU,CAAC,CAAC,CAC5C,EAAE,EAAiB,CAAC;AACzB;AAEA;AACA,SAASZ,eAAe,CAACS,EAAS,EAA8B;EAAA,IAA5BK,8EAA0B,EAAE;EAC5D,KAAK,IAAIC,CAAC,GAAG,CAAC,CAAC,EAAEC,CAAC,GAAG,CAACP,EAAE,IAAI,EAAE,EAAEQ,MAAM,EAAE,EAAEF,CAAC,GAAGC,CAAC,GAAG;IAC9C,MAAMJ,MAAM,GAAGH,EAAE,CAACM,CAAC,CAAC;IACpBH,MAAM,CAAC,UAAU,CAAC,IAAIE,OAAO,CAACI,IAAI,CAAC,IAAIjC,YAAY,CAAC6B,OAAO,CAACG,MAAM,EAAEL,MAAM,CAAC,UAAU,CAAC,CAACK,MAAM,CAAC,CAAC;IAC/FL,MAAM,CAAC,MAAM,CAAC,IAAIE,OAAO,CAACI,IAAI,CAAC,IAAIjC,YAAY,CAAC6B,OAAO,CAACG,MAAM,EAAEL,MAAM,CAAC,MAAM,CAAC,CAACK,MAAM,CAAC,CAAC;IACvFL,MAAM,CAAC,QAAQ,CAAC,IAAIE,OAAO,CAACI,IAAI,CAAC,IAAIjC,YAAY,CAAC6B,OAAO,CAACG,MAAM,EAAEL,MAAM,CAAC,QAAQ,CAAC,CAACK,MAAM,CAAC,CAAC;IAC3FL,MAAM,CAAC,MAAM,CAAC,IAAIE,OAAO,CAACI,IAAI,CAAC,IAAIjC,YAAY,CAAC6B,OAAO,CAACG,MAAM,EAAEL,MAAM,CAAC,MAAM,CAAC,CAACK,MAAM,CAAC,CAAC;IACvFH,OAAO,GAAGd,eAAe,CAACY,MAAM,CAAC,UAAU,CAAC,EAAEE,OAAO,CAAC;;EAE1D,OAAOA,OAAO;AAClB;AAEA;AACA,SAASD,iBAAiB,CAACM,QAAkB;EACzC,OAAO,CAACA,QAAQ,IAAI,EAAE,EAAET,MAAM,CAAC,CAACU,GAAG,EAAEC,GAAG,KAAKD,GAAG,GAAG,EAAEC,GAAG,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC;AACvE;AAEA;AACA,OAAM,SAAUC,aAAa,CAACd,MAAW,EAAEf,YAAoC;EAE3E,IAAI8B,EAAU;EACd,IAAIC,IAAkB;EACtB,IAAIC,KAAmB;EACvB,IAAIC,QAAa;EACjB,IAAIC,IAAmB;EACvB,IAAIC,QAAoB;EAExB;EACA,IAAI,CAACnC,YAAY,IAAI,EAAEiC,QAAQ,GAAGlB,MAAM,CAAC,YAAY,CAAC,CAAC,EAAE;IACrDmB,IAAI,GAAGE,YAAY,CAACrB,MAAM,EAAED,qBAAqB,CAACC,MAAM,EAAEf,YAAY,CAAC,CAAC;IACxEgC,KAAK,GAAG,IAAI/D,KAAK,CAAC8C,MAAM,CAAC,MAAM,CAAC,EAAEmB,IAAI,EAAEnB,MAAM,CAAC,UAAU,CAAC,EAAEZ,sBAAsB,CAACY,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;;EAEjH;EACA;EACA;EACA;EAAA,KACK,IAAI,CAACf,YAAY,CAACqC,GAAG,CAACP,EAAE,GAAGG,QAAQ,CAAC,IAAI,CAAC,CAAC,EAAE;IAC7C;IACAF,IAAI,GAAG,CAACA,IAAI,GAAGE,QAAQ,CAAC,WAAW,CAAC,IAAIK,iBAAiB,CAACP,IAAI,CAAU,GAAG,IAAI3C,KAAK,EAAE;IACtFY,YAAY,CAACuC,GAAG,CAACT,EAAE,EAAEI,IAAI,GAAGE,YAAY,CAACrB,MAAM,EAAED,qBAAqB,CAACC,MAAM,EAAEf,YAAY,CAAC,CAAC,CAAC;IAC9FmC,QAAQ,GAAG,IAAIjE,UAAU,CAACgE,IAAI,EAAEH,IAAI,EAAED,EAAE,EAAEG,QAAQ,CAAC,WAAW,CAAC,CAAC;IAChED,KAAK,GAAG,IAAI/D,KAAK,CAAC8C,MAAM,CAAC,MAAM,CAAC,EAAEoB,QAAQ,EAAEpB,MAAM,CAAC,UAAU,CAAC,EAAEZ,sBAAsB,CAACY,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;;EAErH;EACA;EAAA,KACK;IACD;IACAgB,IAAI,GAAG,CAACA,IAAI,GAAGE,QAAQ,CAAC,WAAW,CAAC,IAAIK,iBAAiB,CAACP,IAAI,CAAU,GAAG,IAAI3C,KAAK,EAAE;IACtF+C,QAAQ,GAAG,IAAIjE,UAAU,CAAC8B,YAAY,CAACwC,GAAG,CAACV,EAAE,CAAE,EAAEC,IAAI,EAAED,EAAE,EAAEG,QAAQ,CAAC,WAAW,CAAC,CAAC;IACjFD,KAAK,GAAG,IAAI/D,KAAK,CAAC8C,MAAM,CAAC,MAAM,CAAC,EAAEoB,QAAQ,EAAEpB,MAAM,CAAC,UAAU,CAAC,EAAEZ,sBAAsB,CAACY,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;;EAErH,OAAOiB,KAAK,IAAI,IAAI;AACxB;AAEA;AACA,SAAS7B,sBAAsB,CAACsC,SAAkB;EAC9C,OAAO,IAAIxC,GAAG,CAAiByC,MAAM,CAACC,OAAO,CAACF,SAAS,IAAI,EAAE,CAAC,CAAC;AACnE;AAEA;AACA,SAASH,iBAAiB,CAACM,KAAU;EACjC,OAAO,IAAI9D,GAAG,CAAC8D,KAAK,CAAC,UAAU,CAAC,EAAEA,KAAK,CAAC,UAAU,CAAC,CAAC;AACxD;AAEA;AACA,SAASR,YAAY,CAACxB,CAAM,EAAEiC,QAAkB;EAE5C,MAAMC,MAAM,GAAGlC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC;EAEhC,QAAQkC,MAAM;IACV,KAAK,MAAM;MAAI,OAAO,IAAIjE,IAAI,EAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAIA,IAAI,EAAE;IAChC,KAAK,QAAQ;MAAE,OAAO,IAAIT,MAAM,EAAE;IAClC,KAAK,MAAM;MAAI,OAAO,IAAID,IAAI,EAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAIS,IAAI,EAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAIL,IAAI,CAAC,CAACsE,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,CAAC;IACnD,KAAK,QAAQ;MAAE,OAAO,IAAInE,MAAM,CAACmE,QAAQ,IAAI,EAAE,CAAC;IAChD,KAAK,SAAS;MAAE,OAAO,IAAInE,MAAM,CAACmE,QAAQ,IAAI,EAAE,CAAC;EAAC;EAGtD,QAAQC,MAAM;IACV,KAAK,KAAK;MAAE;QACR,MAAMC,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI9B,GAAG,CAACiE,CAAC,CAAC,UAAU,CAAC,EAAEA,CAAC,CAAC,UAAU,CAAgB,CAAC;;IAE/D,KAAK,eAAe;MAAE;QAClB,MAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI7B,KAAK,CAACW,SAAS,CAACqD,CAAC,CAAC,WAAW,CAAC,CAAQ,CAAC;;IAEtD,KAAK,SAAS;MAAE;QACZ,MAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIvC,OAAO,CAAC0E,CAAC,CAAC,OAAO,CAAC,EAAEA,CAAC,CAAC,WAAW,CAAC,CAAC;;IAElD,KAAK,MAAM;MAAE;QACT,MAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI5B,KAAK,CAACa,QAAQ,CAACkD,CAAC,CAAC,MAAM,CAAC,CAAQ,CAAC;;IAEhD,KAAK,MAAM;MAAE;QACT,MAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI3B,IAAI,CAACQ,QAAQ,CAACsD,CAAC,CAAC,MAAM,CAAC,CAAQ,EAAEA,CAAC,CAAC,UAAU,CAAiB,CAAC;;IAE9E,KAAK,WAAW;MAAE;QACd,MAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIzB,SAAS,CAACM,QAAQ,CAACsD,CAAC,CAAC,MAAM,CAAC,CAAQ,EAAEA,CAAC,CAAC,UAAU,CAAC,CAAC;;IAEnE,KAAK,UAAU;MAAE;QACb,MAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI1B,QAAQ,CAACS,YAAY,CAACoD,CAAC,CAAC,MAAM,CAAC,CAAQ,CAAC;;IAEvD,KAAK,OAAO;MAAE;QACV,MAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIjC,KAAK,CAACiB,SAAS,CAACmD,CAAC,CAAC,MAAM,CAAC,CAAQ,EAAGA,CAAC,CAAC,SAAS,CAAC,IAAI,EAAE,EAAGF,QAAQ,IAAI,EAAE,CAAC;;IAEvF,KAAK,iBAAiB;MAAE;QACpB,MAAME,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAItC,eAAe,CAACyE,CAAC,CAAC,WAAW,CAAC,CAAC;;IAE9C,KAAK,eAAe;MAAE;QAClB,MAAMA,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAIpC,aAAa,CAACuE,CAAC,CAAC,UAAU,CAAC,EAAE,CAACF,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,CAAC;;IAEhE,KAAK,KAAK;MAAE;QACR,MAAME,CAAC,GAAGnC,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAInC,IAAI,CAAC,CAACoE,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,EAAEE,CAAC,CAAC,YAAY,CAAC,CAAC;;EACxD;EAEL,MAAM,IAAIC,KAAK,CAAC,uBAAuBF,MAAM,GAAG,CAAC;AACrD","names":["Schema","Field","Dictionary","Utf8","Binary","Decimal","FixedSizeBinary","List","FixedSizeList","Map_","Struct","Union","Bool","Null","Int","Float","Date_","Time","Interval","Timestamp","Int32","DictionaryBatch","RecordBatch","FieldNode","BufferRegion","TimeUnit","Precision","IntervalUnit","UnionMode","DateUnit","schemaFromJSON","_schema","dictionaries","Map","schemaFieldsFromJSON","customMetadataFromJSON","recordBatchFromJSON","b","fieldNodesFromJSON","buffersFromJSON","dictionaryBatchFromJSON","filter","Boolean","map","f","fromJSON","fieldChildrenFromJSON","_field","xs","reduce","fieldNodes","column","nullCountFromJSON","buffers","i","n","length","push","validity","sum","val","fieldFromJSON","id","keys","field","dictMeta","type","dictType","typeFromJSON","has","indexTypeFromJSON","set","get","_metadata","Object","entries","_type","children","typeId","t","Error"],"sources":["ipc/metadata/json.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Schema, Field } from '../../schema';\nimport {\n    DataType, Dictionary, TimeBitWidth,\n    Utf8, Binary, Decimal, FixedSizeBinary,\n    List, FixedSizeList, Map_, Struct, Union,\n    Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, IntBitWidth, Int32, TKeys,\n} from '../../type';\n\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n\n/** @ignore */\nexport function schemaFromJSON(_schema: any, dictionaries: Map<number, DataType> = new Map()) {\n    return new Schema(\n        schemaFieldsFromJSON(_schema, dictionaries),\n        customMetadataFromJSON(_schema['customMetadata']),\n        dictionaries\n    );\n}\n\n/** @ignore */\nexport function recordBatchFromJSON(b: any) {\n    return new RecordBatch(\n        b['count'],\n        fieldNodesFromJSON(b['columns']),\n        buffersFromJSON(b['columns'])\n    );\n}\n\n/** @ignore */\nexport function dictionaryBatchFromJSON(b: any) {\n    return new DictionaryBatch(\n        recordBatchFromJSON(b['data']),\n        b['id'], b['isDelta']\n    );\n}\n\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema: any, dictionaries?: Map<number, DataType>) {\n    return (_schema['fields'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldChildrenFromJSON(_field: any, dictionaries?: Map<number, DataType>): Field[] {\n    return (_field['children'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldNodesFromJSON(xs: any[]): FieldNode[] {\n    return (xs || []).reduce<FieldNode[]>((fieldNodes, column: any) => [\n        ...fieldNodes,\n        new FieldNode(\n            column['count'],\n            nullCountFromJSON(column['VALIDITY'])\n        ),\n        ...fieldNodesFromJSON(column['children'])\n    ], [] as FieldNode[]);\n}\n\n/** @ignore */\nfunction buffersFromJSON(xs: any[], buffers: BufferRegion[] = []): BufferRegion[] {\n    for (let i = -1, n = (xs || []).length; ++i < n;) {\n        const column = xs[i];\n        column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n        column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n        column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n        column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n        buffers = buffersFromJSON(column['children'], buffers);\n    }\n    return buffers;\n}\n\n/** @ignore */\nfunction nullCountFromJSON(validity: number[]) {\n    return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n\n/** @ignore */\nexport function fieldFromJSON(_field: any, dictionaries?: Map<number, DataType>) {\n\n    let id: number;\n    let keys: TKeys | null;\n    let field: Field | void;\n    let dictMeta: any;\n    let type: DataType<any>;\n    let dictType: Dictionary;\n\n    // If no dictionary encoding\n    if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n        type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n        field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // tslint:disable\n    // If dictionary encoded and the first time we've seen this dictionary id, decode\n    // the data type and child fields, then wrap in a Dictionary type and insert the\n    // data type into the dictionary types map.\n    else if (!dictionaries.has(id = dictMeta['id'])) {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n        dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n    // data type and wrap in a new Dictionary type and field.\n    else {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictType = new Dictionary(dictionaries.get(id)!, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    return field || null;\n}\n\n/** @ignore */\nfunction customMetadataFromJSON(_metadata?: object) {\n    return new Map<string, string>(Object.entries(_metadata || {}));\n}\n\n/** @ignore */\nfunction indexTypeFromJSON(_type: any) {\n    return new Int(_type['isSigned'], _type['bitWidth']);\n}\n\n/** @ignore */\nfunction typeFromJSON(f: any, children?: Field[]): DataType<any> {\n\n    const typeId = f['type']['name'];\n\n    switch (typeId) {\n        case 'NONE':   return new Null();\n        case 'null':   return new Null();\n        case 'binary': return new Binary();\n        case 'utf8':   return new Utf8();\n        case 'bool':   return new Bool();\n        case 'list':   return new List((children || [])[0]);\n        case 'struct': return new Struct(children || []);\n        case 'struct_': return new Struct(children || []);\n    }\n\n    switch (typeId) {\n        case 'int': {\n            const t = f['type'];\n            return new Int(t['isSigned'], t['bitWidth'] as IntBitWidth);\n        }\n        case 'floatingpoint': {\n            const t = f['type'];\n            return new Float(Precision[t['precision']] as any);\n        }\n        case 'decimal': {\n            const t = f['type'];\n            return new Decimal(t['scale'], t['precision']);\n        }\n        case 'date': {\n            const t = f['type'];\n            return new Date_(DateUnit[t['unit']] as any);\n        }\n        case 'time': {\n            const t = f['type'];\n            return new Time(TimeUnit[t['unit']] as any, t['bitWidth'] as TimeBitWidth);\n        }\n        case 'timestamp': {\n            const t = f['type'];\n            return new Timestamp(TimeUnit[t['unit']] as any, t['timezone']);\n        }\n        case 'interval': {\n            const t = f['type'];\n            return new Interval(IntervalUnit[t['unit']] as any);\n        }\n        case 'union': {\n            const t = f['type'];\n            return new Union(UnionMode[t['mode']] as any, (t['typeIds'] || []), children || []);\n        }\n        case 'fixedsizebinary': {\n            const t = f['type'];\n            return new FixedSizeBinary(t['byteWidth']);\n        }\n        case 'fixedsizelist': {\n            const t = f['type'];\n            return new FixedSizeList(t['listSize'], (children || [])[0]);\n        }\n        case 'map': {\n            const t = f['type'];\n            return new Map_((children || [])[0], t['keysSorted']);\n        }\n    }\n    throw new Error(`Unrecognized type: \"${typeId}\"`);\n}\n"]},"metadata":{},"sourceType":"module"}